{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "426f71b6-ed5c-47f9-9a35-f84920d83a5e",
   "metadata": {},
   "source": [
    "# Federated Averaging (FedAvg) baseline on CIFAR-100\n",
    "- Dirichlet non-IID partitioning\n",
    "- Partial client participation\n",
    "- Optional heterogeneity (per-client batch size / epochs / lr)\n",
    "## Imports and Config values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "129463b1-6d84-4576-b0db-1130acf5bc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict, OrderedDict\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Callable\n",
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms, models\n",
    "from encryption_adapter import SelectiveEncryptionAdapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "74979dd3-9def-4756-a532-dfe7998a51cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    # Federated Learning\n",
    "    \"num_rounds\": 1,\n",
    "    \"num_clients\": 20,\n",
    "    \"clients_per_round\": 5,  # Partial participation\n",
    "    \"local_epochs\": 5,\n",
    "    \"local_batch_size\": 32,\n",
    "\n",
    "    # Data\n",
    "    \"dataset\": \"CIFAR100\",\n",
    "    \"data_root\": \"./data\",\n",
    "    \"alpha\": 0.1,  # Dirichlet concentration (lower = more non-IID)\n",
    "    \"num_classes\": 100,  # 100 for CIFAR-100, 10 for CIFAR-10 etc..\n",
    "\n",
    "    # Model & Training\n",
    "    \"model_arch\": \"resnet18\",\n",
    "    \"optimizer\": \"SGD\",\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 5e-4,\n",
    "\n",
    "    # Capture settings\n",
    "    \"max_steps_to_store\": None,  # None = store all, or set limit (e.g., 50)\n",
    "    \"return_indices\": False,\n",
    "\n",
    "    # Misc\n",
    "    \"device\": \"cuda\",\n",
    "    \"seed\": 42,\n",
    "\n",
    "    # Persistence\n",
    "    \"artifact_root\": \"./reports\",\n",
    "    \"experiment_name\": \"fedavg_baseline\",\n",
    "    \"save_prefix\": \"fedavg_metrics\",\n",
    "    \"persist_client_payloads\": True,\n",
    "    \"persist_round_metrics\": True,\n",
    "    \"persist_config_snapshot\": True,\n",
    "\n",
    "    # Privacy settings\n",
    "    \"enable_dp\": False,           # Enable differential privacy\n",
    "    \"clip_norm\": 1.0,             # Gradient clipping threshold\n",
    "    \"noise_multiplier\": 1.0,      # Noise scaling factor for differential privacy\n",
    "    \"target_delta\": 1e-5,         # Target delta parameter for DP\n",
    "\n",
    "   # Encryption settings\n",
    "    \"enable_encryption\": False,   # Enable encryption\n",
    "    \"layers_to_encrypt\": [\"fc\"],  # Encrypt only the fully connected (fc) layer\n",
    "\n",
    "    \"enable_secure_aggregation\": False,   # Enable secure aggregation\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "09bcf5a5-460e-4466-a956-92218dd09def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "random.seed(CONFIG[\"seed\"])\n",
    "np.random.seed(CONFIG[\"seed\"])\n",
    "torch.manual_seed(CONFIG[\"seed\"])\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(CONFIG[\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2c3883ac-cae3-4768-aef6-cedd85c8370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "def to_cpu_f32(t):\n",
    "    return t.detach().to(\"cpu\", non_blocking=True).float().clone()\n",
    "\n",
    "def state_to_cpu_f32(sd: dict):\n",
    "    return {k: to_cpu_f32(v) for k, v in sd.items()}\n",
    "\n",
    "def param_order_and_shapes(model: torch.nn.Module):\n",
    "    return [{\"name\": n, \"shape\": list(p.shape), \"numel\": p.numel()} \n",
    "            for n, p in model.named_parameters()]\n",
    "\n",
    "@dataclass\n",
    "class OptimCfg:\n",
    "    name: str = \"SGD\"\n",
    "    lr: float = 0.01\n",
    "    momentum: float = 0.9\n",
    "    weight_decay: float = 5e-4\n",
    "    nesterov: bool = False\n",
    "\n",
    "def build_optimizer(model, cfg: OptimCfg):\n",
    "    if cfg.name.lower() == \"sgd\":\n",
    "        return optim.SGD(model.parameters(), lr=cfg.lr, momentum=cfg.momentum,\n",
    "                         weight_decay=cfg.weight_decay, nesterov=cfg.nesterov)\n",
    "    elif cfg.name.lower() == \"adam\":\n",
    "        return optim.Adam(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported optimizer: {cfg.name}\")\n",
    "\n",
    "def class_histogram_from_loader(loader, num_classes: int):\n",
    "    counts = torch.zeros(num_classes, dtype=torch.long)\n",
    "    for batch in loader:\n",
    "        y = batch[1]\n",
    "        counts.index_add_(0, y.to(dtype=torch.long), torch.ones_like(y, dtype=torch.long))\n",
    "    return {int(i): int(v) for i, v in enumerate(counts)}\n",
    "\n",
    "def ensure_dir(path: Path):\n",
    "    Path(path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def seed_worker(worker_id: int):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "def flatten_state_dict(state: dict):\n",
    "    parts = []\n",
    "    keys = []\n",
    "    shapes = []\n",
    "    dtypes = []\n",
    "    for k, v in state.items():\n",
    "        tensor = v.detach().cpu()\n",
    "        parts.append(tensor.reshape(-1).float())\n",
    "        keys.append(k)\n",
    "        shapes.append(list(tensor.shape))\n",
    "        dtypes.append(str(tensor.dtype))\n",
    "    flat = torch.cat(parts, dim=0) if parts else torch.tensor([], dtype=torch.float32)\n",
    "    template = {\"keys\": keys, \"shapes\": shapes, \"dtypes\": dtypes}\n",
    "    return flat, template\n",
    "\n",
    "def dict_tensor_nbytes(tensor_map: dict) -> int:\n",
    "    total = 0\n",
    "    for value in tensor_map.values():\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            total += value.element_size() * value.numel()\n",
    "    return int(total)\n",
    "\n",
    "def dict_tensor_norm(tensor_map: dict) -> float:\n",
    "    total = 0.0\n",
    "    for value in tensor_map.values():\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            total += float(value.float().pow(2).sum().item())\n",
    "    return float(math.sqrt(total)) if total > 0.0 else 0.0\n",
    "\n",
    "def json_default(obj):\n",
    "    if isinstance(obj, Path):\n",
    "        return str(obj)\n",
    "    if isinstance(obj, torch.device):\n",
    "        return str(obj)\n",
    "    if isinstance(obj, np.generic):\n",
    "        return obj.item()\n",
    "    raise TypeError(f\"Object of type {type(obj).__name__} is not JSON serializable\")\n",
    "\n",
    "def save_client_update(\n",
    "    experiment_dir: Path,\n",
    "    round_idx: int,\n",
    "    client_id: int,\n",
    "    global_state: dict,\n",
    "    local_state: dict,\n",
    "    shard_size: int,\n",
    "    lr: float,\n",
    "    epochs: int,\n",
    "    extra_meta: Optional[dict] = None,\n",
    ") -> Path:\n",
    "    round_dir = Path(experiment_dir) / f\"round_{int(round_idx):02d}\"\n",
    "    ensure_dir(round_dir)\n",
    "\n",
    "    local_flat, template = flatten_state_dict(local_state)\n",
    "    global_flat, _ = flatten_state_dict(global_state)\n",
    "    delta = (local_flat - global_flat).cpu()\n",
    "\n",
    "    meta = {\n",
    "        \"round\": int(round_idx),\n",
    "        \"client_id\": int(client_id),\n",
    "        \"shard_size\": int(shard_size),\n",
    "        \"lr\": float(lr),\n",
    "        \"epochs\": int(epochs),\n",
    "    }\n",
    "    if extra_meta:\n",
    "        meta.update(extra_meta)\n",
    "\n",
    "    payload = {\n",
    "        \"delta\": delta,\n",
    "        \"template\": template,\n",
    "        \"meta\": meta,\n",
    "    }\n",
    "\n",
    "    path = round_dir / f\"client_{client_id}.pt\"\n",
    "    torch.save(payload, path)\n",
    "    return path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640693cd-8558-4039-94a6-73e1c7310bb8",
   "metadata": {},
   "source": [
    "### Data: CIFAR-100 loaders (train/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "339ab6c7-e890-45c8-a328-58abc50f6b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar100(data_root: str = \"./data\"):\n",
    "    mean = (0.5071, 0.4867, 0.4408)\n",
    "    std = (0.2675, 0.2565, 0.2761)\n",
    "    \n",
    "    train_tf = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ])\n",
    "    test_tf = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ])\n",
    "    \n",
    "    train = datasets.CIFAR100(root=data_root, train=True, download=True, transform=train_tf)\n",
    "    test = datasets.CIFAR100(root=data_root, train=False, download=True, transform=test_tf)\n",
    "    return train, test\n",
    "\n",
    "def _get_targets(dataset) -> np.ndarray:\n",
    "    targets = getattr(dataset, \"targets\", None)\n",
    "    if targets is None:\n",
    "        targets = getattr(dataset, \"labels\", None)\n",
    "    if targets is None:\n",
    "        raise AttributeError(\"Dataset has no 'targets' or 'labels'.\")\n",
    "    return np.array(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181cb369-91c8-4418-9c36-7c8d1066c6ad",
   "metadata": {},
   "source": [
    "Dirichlet non-IID split (returns dict: client_id -> list of indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3ffb5136-9ee7-4c9e-91b3-93cb31543de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dirichlet_noniid_indices(dataset, num_clients: int, alpha: float, \n",
    "                             min_per_client: int = 10) -> Dict[int, List[int]]:\n",
    "    y = _get_targets(dataset)\n",
    "    num_classes = int(y.max()) + 1\n",
    "    idx_by_class = {c: np.where(y == c)[0] for c in range(num_classes)}\n",
    "    for c in idx_by_class:\n",
    "        np.random.shuffle(idx_by_class[c])\n",
    "    \n",
    "    client_indices = [[] for _ in range(num_clients)]\n",
    "    for c in range(num_classes):\n",
    "        idx_c = idx_by_class[c]\n",
    "        if len(idx_c) == 0:\n",
    "            continue\n",
    "        p = np.random.dirichlet([alpha] * num_clients)\n",
    "        cuts = (np.cumsum(p) * len(idx_c)).astype(int)[:-1]\n",
    "        split = np.split(idx_c, cuts)\n",
    "        for i, shard in enumerate(split):\n",
    "            client_indices[i].extend(shard.tolist())\n",
    "    \n",
    "    pool = list(range(len(dataset)))\n",
    "    for i in range(num_clients):\n",
    "        if len(client_indices[i]) < min_per_client:\n",
    "            need = min_per_client - len(client_indices[i])\n",
    "            extra = np.random.choice(pool, size=need, replace=False).tolist()\n",
    "            client_indices[i].extend(extra)\n",
    "    \n",
    "    for i in range(num_clients):\n",
    "        random.shuffle(client_indices[i])\n",
    "    return {i: client_indices[i] for i in range(num_clients)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1ab77a-7051-4c8a-a378-17572b213790",
   "metadata": {},
   "source": [
    "### Model: ResNet18 head for CIFAR-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ed2e60c4-fe88-4517-82d1-6a378cec15bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_classes: int = 100) -> nn.Module:\n",
    "    model = models.resnet18(weights=None)  # no pretrained to avoid download in restricted envs\n",
    "    # CIFAR images are 3x32x32; torchvision ResNet expects 224x224,\n",
    "    # but it's fineâ€”ResNet is fully conv except FC. It still works on 32x32.\n",
    "    # Replace final FC layer to match number of classes\n",
    "    in_feats = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_feats, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e4147e8a-70fb-4f6d-8ef4-47f142fbeea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: nn.Module, loader: DataLoader, device: torch.device) -> Tuple[float, float]:\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss_sum = 0.0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            loss_sum += loss.item() * x.size(0)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += x.size(0)\n",
    "    return loss_sum / max(1, total), correct / max(1, total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2a53dc-5017-4571-801b-cca18e22badd",
   "metadata": {},
   "source": [
    "###  Local Training with Gradient Capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "51d75124-15ce-4c2b-9faa-7a66984edd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def clone_state(model):\n",
    "    return {k: v.detach().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "def train_one_client_with_capture(\n",
    "    global_model: nn.Module,\n",
    "    client_loader: DataLoader,\n",
    "    loss_fn: nn.Module,\n",
    "    opt_cfg: OptimCfg,\n",
    "    epochs: int = 1,\n",
    "    device: torch.device = torch.device(\"cpu\"),\n",
    "    max_steps_to_store: int = None,\n",
    "    return_indices: bool = False,\n",
    "    num_classes: int = None,\n",
    "    client_seed: int = None,\n",
    "    clip_norm: float = None,  # Gradient clipping threshold for privacy\n",
    "):\n",
    "    # Create local copy of global model\n",
    "    model = copy.deepcopy(global_model).to(device)\n",
    "    model.train()\n",
    "    \n",
    "    # Set client-specific seed for reproducibility\n",
    "    if client_seed is not None:\n",
    "        torch.manual_seed(client_seed)\n",
    "        random.seed(client_seed)\n",
    "        np.random.seed(client_seed)\n",
    "    \n",
    "    # Save initial state to compute delta later\n",
    "    global_before = clone_state(model)\n",
    "    opt = build_optimizer(model, opt_cfg)\n",
    "    \n",
    "    # Storage for captured gradients and metadata\n",
    "    grads_per_step_raw = []\n",
    "    grads_per_step_wd = []\n",
    "    batch_sizes = []\n",
    "    step_losses = []\n",
    "    step_batch_indices = []\n",
    "    \n",
    "    steps_stored = 0\n",
    "    \n",
    "    # Local training loop\n",
    "    for _ in range(epochs):\n",
    "        for batch in client_loader:\n",
    "            # Handle batch with or without indices\n",
    "            if return_indices and len(batch) == 3:\n",
    "                x, y, idxs = batch\n",
    "            else:\n",
    "                x, y = batch[0], batch[1]\n",
    "                idxs = None\n",
    "            \n",
    "            x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "            \n",
    "            # Forward pass and backward\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            logits = model(x)\n",
    "            loss = loss_fn(logits, y)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient Clipping\n",
    "            if clip_norm is not None and clip_norm > 0:\n",
    "                # Compute total gradient norm (L2)\n",
    "                total_norm = 0.0\n",
    "                for p in model.parameters():\n",
    "                    if p.grad is not None:\n",
    "                        total_norm += p.grad.data.norm(2).item() ** 2\n",
    "                total_norm = total_norm ** 0.5\n",
    "                \n",
    "                # Clip if norm exceeds threshold\n",
    "                if total_norm > clip_norm:\n",
    "                    clip_coef = clip_norm / (total_norm + 1e-6)\n",
    "                    for p in model.parameters():\n",
    "                        if p.grad is not None:\n",
    "                            p.grad.data.mul_(clip_coef)\n",
    "            \n",
    "            # Store gradients (after clipping)\n",
    "            if max_steps_to_store is None or steps_stored < max_steps_to_store:\n",
    "                raw_dict = {}\n",
    "                wd_dict = {}\n",
    "                \n",
    "                # Iterate through all parameters\n",
    "                for name, p in model.named_parameters():\n",
    "                    if p.grad is None:\n",
    "                        continue\n",
    "                    \n",
    "                    g = p.grad\n",
    "                    # Store raw gradient (clipped if clip_norm is set)\n",
    "                    raw_dict[name] = to_cpu_f32(g)\n",
    "                    \n",
    "                    # Store gradient with weight decay applied\n",
    "                    if opt_cfg.weight_decay and opt_cfg.weight_decay > 0:\n",
    "                        wd_dict[name] = to_cpu_f32(g + opt_cfg.weight_decay * p.data)\n",
    "                    else:\n",
    "                        wd_dict[name] = to_cpu_f32(g)\n",
    "                \n",
    "                # Append to storage\n",
    "                grads_per_step_raw.append(raw_dict)\n",
    "                grads_per_step_wd.append(wd_dict)\n",
    "                batch_sizes.append(int(x.shape[0]))\n",
    "                step_losses.append(float(loss.detach().item()))\n",
    "                \n",
    "                if return_indices and idxs is not None:\n",
    "                    step_batch_indices.append([int(i) for i in idxs])\n",
    "                \n",
    "                steps_stored += 1\n",
    "            \n",
    "            # Update model parameters\n",
    "            opt.step()\n",
    "    \n",
    "    # Get final local state\n",
    "    local_after = clone_state(model)\n",
    "    \n",
    "    # Compute update delta (local_state - global_state)\n",
    "    delta = OrderedDict()\n",
    "    for k in local_after.keys():\n",
    "        delta[k] = to_cpu_f32(local_after[k]) - to_cpu_f32(global_before[k])\n",
    "    \n",
    "    # Compute gradient statistics\n",
    "    if len(grads_per_step_raw) > 0:\n",
    "        first_step = grads_per_step_raw[0]\n",
    "        # Per-layer gradient norms\n",
    "        per_layer_norms = {k: float(v.view(-1).norm().item()) for k, v in first_step.items()}\n",
    "        # Total gradient norm\n",
    "        grad_norm_total = float(torch.sqrt(sum(v.pow(2).sum() for v in first_step.values())).item())\n",
    "    else:\n",
    "        per_layer_norms, grad_norm_total = {}, 0.0\n",
    "    \n",
    "    # Class distribution histogram\n",
    "    class_dist = None\n",
    "    if num_classes is not None:\n",
    "        class_dist = class_histogram_from_loader(client_loader, num_classes=num_classes)\n",
    "    \n",
    "    # Package telemetry\n",
    "    telemetry = {\n",
    "        \"per_layer_norms\": per_layer_norms,\n",
    "        \"gradient_norm\": grad_norm_total,\n",
    "        \"loss_history\": step_losses,\n",
    "        \"batch_sizes\": batch_sizes,\n",
    "        \"num_steps_captured\": len(grads_per_step_raw),\n",
    "        \"num_samples\": sum(batch_sizes),\n",
    "        \"class_distribution\": class_dist,\n",
    "    }\n",
    "    \n",
    "    if return_indices and len(step_batch_indices) > 0:\n",
    "        telemetry[\"batch_indices\"] = step_batch_indices\n",
    "    \n",
    "    # Return complete training result\n",
    "    return {\n",
    "        \"local_state_after\": state_to_cpu_f32(local_after),\n",
    "        \"delta\": delta,\n",
    "        \"grads_per_step_raw\": grads_per_step_raw,      # Raw gradients (clipped)\n",
    "        \"grads_per_step_wd\": grads_per_step_wd,        # Gradients with weight decay\n",
    "        \"telemetry\": telemetry,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b2afc1-e8b4-4d9f-ba4f-0ade607afdfb",
   "metadata": {},
   "source": [
    "### FedAvg Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2b7ff223-24df-4e1d-88e1-66f41d5fa6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_weights(weight_list, sizes):\n",
    "    if not weight_list:\n",
    "        raise ValueError(\"No client weights provided.\")\n",
    "    if len(weight_list) != len(sizes):\n",
    "        raise ValueError(\"weights and sizes mismatch\")\n",
    "    \n",
    "    # Compute total samples across all clients\n",
    "    total = float(sum(sizes))\n",
    "    \n",
    "    # Initialize averaged weights with zeros\n",
    "    avg = {k: torch.zeros_like(v) for k, v in weight_list[0].items()}\n",
    "    \n",
    "    # Weighted sum: avg = sum(weight_i * size_i / total_size)\n",
    "    for wi, si in zip(weight_list, sizes):\n",
    "        w = si / total  # Weight for this client\n",
    "        for k in avg.keys():\n",
    "            if avg[k].dtype.is_floating_point:\n",
    "                # Floating point parameters: weighted average\n",
    "                avg[k] += wi[k].float() * w\n",
    "            else:\n",
    "                # Non-floating point (e.g., batch norm buffers): copy last value\n",
    "                avg[k] = wi[k].clone()\n",
    "    \n",
    "    return avg\n",
    "\n",
    "def secure_aggregate_stub(weight_list, sizes, enabled: bool = False):\n",
    "    if not enabled:\n",
    "        # When disabled, fall back to standard FedAvg\n",
    "        return average_weights(weight_list, sizes)\n",
    "    \n",
    "    print(\"Using secure aggregation (stub)\")\n",
    "    return average_weights(weight_list, sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c37ebcf-4a6f-43b0-b8de-33a93110910a",
   "metadata": {},
   "source": [
    "## Federated Round with Capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ef678f95-631a-4348-b079-afee529f6c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fed_round_with_capture(\n",
    "    round_num: int,\n",
    "    global_model: nn.Module,\n",
    "    clients: dict,\n",
    "    loss_fn: nn.Module,\n",
    "    opt_cfg: OptimCfg,\n",
    "    local_epochs: int,\n",
    "    device: torch.device,\n",
    "    num_classes: int = None,\n",
    "    max_steps_to_store: int = None,\n",
    "    return_indices: bool = False,\n",
    "    server_seed: int = None,\n",
    "    client_seeds: dict = None,\n",
    "    training_meta: dict = None,\n",
    "    global_eval_fn = None,\n",
    "    clip_norm: float = None,              # Gradient clipping for DP\n",
    "    encryption_adapter = None,            # Optional encryption for gradients/updates\n",
    "    client_callback: Optional[Callable[[int, int, dict, dict], None]] = None,\n",
    "):\n",
    "    # Set server-side seeds for reproducibility (optional)\n",
    "    if server_seed is not None:\n",
    "        torch.manual_seed(server_seed)\n",
    "        random.seed(server_seed)\n",
    "        np.random.seed(server_seed)\n",
    "\n",
    "    # Participating clients (keys of the provided loaders)\n",
    "    participating_clients = list(clients.keys())\n",
    "    # Save the current global model (for deltas and logging)\n",
    "    global_state_cpu = state_to_cpu_f32(global_model.state_dict())\n",
    "\n",
    "    # Per-round containers\n",
    "    client_metrics, raw_gradients, model_updates = {}, {}, {}\n",
    "\n",
    "    # Local training on each client (with gradient capture)\n",
    "    for cid, loader in clients.items():\n",
    "        cseed = (client_seeds or {}).get(cid)\n",
    "        result = train_one_client_with_capture(\n",
    "            global_model=global_model,\n",
    "            client_loader=loader,\n",
    "            loss_fn=loss_fn,\n",
    "            opt_cfg=opt_cfg,\n",
    "            epochs=local_epochs,\n",
    "            device=device,\n",
    "            max_steps_to_store=max_steps_to_store,\n",
    "            return_indices=return_indices,\n",
    "            num_classes=num_classes,\n",
    "            client_seed=cseed,\n",
    "            clip_norm=clip_norm,  # per-batch gradient clipping inside client (optional)\n",
    "        )\n",
    "\n",
    "        # Optionally encrypt first-step gradients (demo / selective-layer)\n",
    "        if encryption_adapter and encryption_adapter.enabled:\n",
    "            encrypted_grads = encryption_adapter.encrypt_gradients(\n",
    "                result[\"grads_per_step_raw\"][0]\n",
    "            )\n",
    "            result[\"encrypted_grads\"] = encrypted_grads\n",
    "\n",
    "        # Save client delta and raw gradients (for attacks/eval)\n",
    "        model_updates[cid] = result[\"delta\"]\n",
    "        raw_gradients[cid] = {\n",
    "            \"grads_per_step_raw\": result[\"grads_per_step_raw\"],\n",
    "            \"grads_per_step_wd\": result[\"grads_per_step_wd\"],\n",
    "        }\n",
    "\n",
    "        # Build client metrics (sizes, losses, norms, etc.)\n",
    "        delta_bytes = dict_tensor_nbytes(result[\"delta\"])\n",
    "        delta_norm = dict_tensor_norm(result[\"delta\"])\n",
    "        tele = result[\"telemetry\"]\n",
    "        client_metrics[cid] = {\n",
    "            \"gradient_norm\": tele[\"gradient_norm\"],\n",
    "            \"per_layer_norms\": tele[\"per_layer_norms\"],\n",
    "            \"local_epochs\": local_epochs,\n",
    "            \"learning_rate\": opt_cfg.lr,\n",
    "            \"num_samples\": tele[\"num_samples\"],\n",
    "            \"class_distribution\": tele[\"class_distribution\"],\n",
    "            \"local_loss\": float(tele[\"loss_history\"][-1]) if tele[\"loss_history\"] else None,\n",
    "            \"loss_history\": tele[\"loss_history\"],\n",
    "            \"batch_sizes\": tele[\"batch_sizes\"],\n",
    "            \"num_steps_captured\": tele.get(\"num_steps_captured\"),\n",
    "            \"update_norm\": delta_norm,\n",
    "            \"upload_bytes\": delta_bytes,\n",
    "            \"seed\": cseed,\n",
    "        }\n",
    "        if return_indices and (\"batch_indices\" in tele):\n",
    "            client_metrics[cid][\"batch_indices\"] = tele[\"batch_indices\"]\n",
    "\n",
    "        # Optional per-client save hook (e.g., write payloads to disk)\n",
    "        if callable(client_callback):\n",
    "            client_callback(round_num, cid, result, global_state_cpu)\n",
    "\n",
    "        # Optionally encrypt the model update itself (selective-layer)\n",
    "        if encryption_adapter and encryption_adapter.enabled:\n",
    "            result[\"encrypted_update\"] = encryption_adapter.encrypt_update(result[\"delta\"])\n",
    "\n",
    "    # Per-client clipping on updates (client-level DP)\n",
    "    clip_C = CONFIG.get(\"clip_norm\")\n",
    "    if clip_C and clip_C > 0:\n",
    "        for _cid, _delta in model_updates.items():\n",
    "            _sq = 0.0\n",
    "            for _v in _delta.values():\n",
    "                if isinstance(_v, torch.Tensor):\n",
    "                    _sq += float(_v.detach().float().pow(2).sum().item())\n",
    "            _norm = math.sqrt(_sq) if _sq > 0.0 else 0.0\n",
    "            if _norm > clip_C:\n",
    "                _coef = clip_C / (_norm + 1e-6)\n",
    "                for _k, _v in _delta.items():\n",
    "                    if isinstance(_v, torch.Tensor):\n",
    "                        _delta[_k] = _v * _coef\n",
    "\n",
    "    # Aggregate updates: secure-agg stub or standard FedAvg\n",
    "    agg_delta = {}\n",
    "    if len(model_updates) > 0:\n",
    "        keys = next(iter(model_updates.values())).keys()\n",
    "        sizes = [client_metrics[cid][\"num_samples\"] for cid in participating_clients]\n",
    "        total_samples = float(sum(sizes)) if sizes else 0.0\n",
    "\n",
    "        use_secure_agg = CONFIG.get(\"enable_secure_aggregation\", False)\n",
    "        if use_secure_agg:\n",
    "            # Stub: behaves like weighted average, but hides per-client intermediates\n",
    "            agg_delta = secure_aggregate_stub(  \n",
    "                list(model_updates.values()),\n",
    "                sizes,\n",
    "                enabled=True\n",
    "            )\n",
    "        else:\n",
    "            # Standard FedAvg weighted average by #samples\n",
    "            for k in keys:\n",
    "                agg = torch.zeros_like(model_updates[participating_clients[0]][k])\n",
    "                for cid, size in zip(participating_clients, sizes):\n",
    "                    weight = float(size) / total_samples if total_samples > 0 else 0.0\n",
    "                    agg = agg + model_updates[cid][k] * weight\n",
    "                agg_delta[k] = agg\n",
    "\n",
    "    # Add DP noise AFTER aggregation (client-level DP noise)\n",
    "    if CONFIG.get(\"enable_dp\", False):\n",
    "        clip_C = CONFIG.get(\"clip_norm\", 1.0)\n",
    "        sigma = clip_C * CONFIG.get(\"noise_multiplier\", 1.0)\n",
    "        for k, v in list(agg_delta.items()):\n",
    "            if isinstance(v, torch.Tensor) and v.dtype.is_floating_point:\n",
    "                agg_delta[k] = v + torch.normal(\n",
    "                    mean=0.0, std=sigma, size=v.shape, device=v.device, dtype=v.dtype\n",
    "                )\n",
    "\n",
    "    # Optional global evaluation callback\n",
    "    global_accuracy = None\n",
    "    global_loss = None\n",
    "    if callable(global_eval_fn):\n",
    "        global_loss, global_accuracy = global_eval_fn(global_model)\n",
    "\n",
    "    # Snapshot the configuration context for this round\n",
    "    config_snapshot = {\n",
    "        \"arch\": type(global_model).__name__,\n",
    "        \"optimizer\": asdict(opt_cfg),\n",
    "        \"loss\": type(loss_fn).__name__,\n",
    "        \"num_classes\": num_classes,\n",
    "        \"param_meta\": param_order_and_shapes(global_model),\n",
    "        \"seeds\": {\"server_seed\": server_seed, \"client_seeds\": client_seeds},\n",
    "        \"device\": str(device),\n",
    "    }\n",
    "    if training_meta:\n",
    "        config_snapshot.update({\"training_meta\": training_meta})\n",
    "\n",
    "    # Round-level stats (norms, counts)\n",
    "    update_norms = {int(cid): client_metrics[cid][\"update_norm\"] for cid in participating_clients}\n",
    "    norm_values = np.array(list(update_norms.values()), dtype=float) if update_norms else np.array([], dtype=float)\n",
    "    round_stats = {\n",
    "        \"update_norms\": update_norms,\n",
    "        \"server_delta_norm\": dict_tensor_norm(agg_delta),\n",
    "        \"avg_update_norm\": float(norm_values.mean()) if norm_values.size else 0.0,\n",
    "        \"std_update_norm\": float(norm_values.std()) if norm_values.size > 1 else 0.0,\n",
    "        \"max_update_norm\": float(norm_values.max()) if norm_values.size else 0.0,\n",
    "        \"min_update_norm\": float(norm_values.min()) if norm_values.size else 0.0,\n",
    "        \"num_participating_clients\": len(participating_clients),\n",
    "    }\n",
    "\n",
    "    # Communication accounting (server broadcast + client uploads)\n",
    "    client_upload_details = {int(cid): int(client_metrics[cid][\"upload_bytes\"]) for cid in participating_clients}\n",
    "    communication_bytes = {\n",
    "        \"server_broadcast\": dict_tensor_nbytes(global_state_cpu),\n",
    "        \"client_upload_total\": int(sum(client_upload_details.values())),\n",
    "        \"client_upload_per_client\": client_upload_details,\n",
    "    }\n",
    "\n",
    "    # Return full round summary\n",
    "    return {\n",
    "        \"round\": int(round_num),\n",
    "        \"participating_clients\": participating_clients,\n",
    "        \"client_metrics\": client_metrics,\n",
    "        \"global_model_state\": global_state_cpu,\n",
    "        \"global_accuracy\": global_accuracy,\n",
    "        \"global_loss\": global_loss,\n",
    "        \"raw_gradients\": raw_gradients,\n",
    "        \"model_updates\": model_updates,\n",
    "        \"server_aggregate_delta\": agg_delta,\n",
    "        \"config_snapshot\": config_snapshot,\n",
    "        \"round_stats\": round_stats,\n",
    "        \"communication_bytes\": communication_bytes,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df6900b-5545-4c70-beb3-a847992afc01",
   "metadata": {},
   "source": [
    "## Save Exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "62121657-e9f6-400b-9980-f3b76d35b393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "\n",
    "def save_round_export(\n",
    "    metrics_to_export,\n",
    "    experiment_dir: Path,\n",
    "    prefix: str = \"fed_round\",\n",
    "    persist_json: bool = True,\n",
    "):\n",
    "    r = metrics_to_export[\"round\"]\n",
    "    ensure_dir(experiment_dir)\n",
    "    round_dir = Path(experiment_dir) / f\"round_{r:02d}\"\n",
    "    ensure_dir(round_dir)\n",
    "\n",
    "    tensor_blob = {\n",
    "        \"global_model_state\": metrics_to_export[\"global_model_state\"],\n",
    "        \"raw_gradients\": metrics_to_export[\"raw_gradients\"],\n",
    "        \"model_updates\": metrics_to_export[\"model_updates\"],\n",
    "        \"server_aggregate_delta\": metrics_to_export.get(\"server_aggregate_delta\"),\n",
    "    }\n",
    "    meta_blob = {\n",
    "        k: v\n",
    "        for k, v in metrics_to_export.items()\n",
    "        if k not in tensor_blob.keys()\n",
    "    }\n",
    "\n",
    "    tensor_path = round_dir / f\"{prefix}_{r:02d}_tensors.pt\"\n",
    "    torch.save(tensor_blob, tensor_path)\n",
    "\n",
    "    meta_path = None\n",
    "    if persist_json:\n",
    "        meta_path = round_dir / f\"{prefix}_{r:02d}_meta.json\"\n",
    "        with open(meta_path, \"w\") as f:\n",
    "            json.dump(meta_blob, f, indent=2, default=json_default)\n",
    "    else:\n",
    "        meta_path = round_dir / f\"{prefix}_{r:02d}_meta.pkl\"\n",
    "        with open(meta_path, \"wb\") as f:\n",
    "            pickle.dump(meta_blob, f)\n",
    "\n",
    "    return {\n",
    "        \"round_dir\": str(round_dir),\n",
    "        \"tensor_path\": str(tensor_path),\n",
    "        \"meta_path\": str(meta_path) if meta_path else None,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb72276a-9d1b-47fe-8d8d-014832f70ea4",
   "metadata": {},
   "source": [
    "## Final / main executionn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7cb95684-ccc1-4760-97e0-248f8687d1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FedAvg Training with Gradient Capture\n",
      "Device preference: cuda\n",
      "Resolved device: cpu\n",
      "Rounds: 1\n",
      "Clients: 20 (sampling 5/round)\n",
      "Local epochs: 5\n",
      "Alpha (non-IID): 0.1\n",
      "____________________________________________________________________________________________________\n",
      "\n",
      "[1/5] Loading data...\n",
      "[2/5] Partitioning data (Dirichlet non-IID)...\n",
      "   Client data sizes: [2379, 2491, 2850, 1844, 2196, 3684, 2712, 2848, 1882, 1325, 2853, 2762, 3032, 2282, 1604, 2385, 3192, 2242, 3007, 2430]\n",
      "[3/5] Building model...\n",
      "DP disabled\n",
      "[4/5] Starting federated training...\n",
      "\n",
      "--- Round 1/1 ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 176\u001b[0m\n\u001b[1;32m    173\u001b[0m client_seeds \u001b[38;5;241m=\u001b[39m {cid: CONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m round_num \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mint\u001b[39m(cid) \u001b[38;5;28;01mfor\u001b[39;00m cid \u001b[38;5;129;01min\u001b[39;00m participating} \u001b[38;5;28;01mif\u001b[39;00m CONFIG\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;66;03m# RUN ONE FEDERATED ROUND\u001b[39;00m\n\u001b[0;32m--> 176\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mrun_fed_round_with_capture\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mround_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mround_num\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobal_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mglobal_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mselected_loaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopt_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlocal_epochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_classes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_steps_to_store\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_steps_to_store\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreturn_indices\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_seeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_seeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_meta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43malpha\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43malpha\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobal_eval_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclip_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclip_norm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# Pass gradient clipping\u001b[39;49;00m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencryption_adapter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencryption_adapter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# Pass encryption adapter\u001b[39;49;00m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_callback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# Record timing\u001b[39;00m\n\u001b[1;32m    197\u001b[0m metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mround_wall_time_sec\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter() \u001b[38;5;241m-\u001b[39m round_start\n",
      "Cell \u001b[0;32mIn[77], line 37\u001b[0m, in \u001b[0;36mrun_fed_round_with_capture\u001b[0;34m(round_num, global_model, clients, loss_fn, opt_cfg, local_epochs, device, num_classes, max_steps_to_store, return_indices, server_seed, client_seeds, training_meta, global_eval_fn, clip_norm, encryption_adapter, client_callback)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cid, loader \u001b[38;5;129;01min\u001b[39;00m clients\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     36\u001b[0m     cseed \u001b[38;5;241m=\u001b[39m (client_seeds \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(cid)\n\u001b[0;32m---> 37\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_client_with_capture\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mglobal_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mglobal_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopt_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_steps_to_store\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_steps_to_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclip_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclip_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# per-batch gradient clipping inside client (optional)\u001b[39;49;00m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;66;03m# Optionally encrypt first-step gradients (demo / selective-layer)\u001b[39;00m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m encryption_adapter \u001b[38;5;129;01mand\u001b[39;00m encryption_adapter\u001b[38;5;241m.\u001b[39menabled:\n",
      "Cell \u001b[0;32mIn[75], line 91\u001b[0m, in \u001b[0;36mtrain_one_client_with_capture\u001b[0;34m(global_model, client_loader, loss_fn, opt_cfg, epochs, device, max_steps_to_store, return_indices, num_classes, client_seed, clip_norm)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# Store gradient with weight decay applied\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_cfg\u001b[38;5;241m.\u001b[39mweight_decay \u001b[38;5;129;01mand\u001b[39;00m opt_cfg\u001b[38;5;241m.\u001b[39mweight_decay \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 91\u001b[0m     wd_dict[name] \u001b[38;5;241m=\u001b[39m \u001b[43mto_cpu_f32\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mopt_cfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     wd_dict[name] \u001b[38;5;241m=\u001b[39m to_cpu_f32(g)\n",
      "Cell \u001b[0;32mIn[70], line 3\u001b[0m, in \u001b[0;36mto_cpu_f32\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mto_cpu_f32\u001b[39m(t):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"FedAvg Training with Gradient Capture\")\n",
    "    print(f\"Device preference: {CONFIG['device']}\")\n",
    "    \n",
    "    # Resolve device (prefer CUDA, fallback to MPS or CPU)\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    print(f\"Resolved device: {device}\")\n",
    "    \n",
    "    # Display training configuration\n",
    "    print(f\"Rounds: {CONFIG['num_rounds']}\")\n",
    "    print(f\"Clients: {CONFIG['num_clients']} (sampling {CONFIG['clients_per_round']}/round)\")\n",
    "    print(f\"Local epochs: {CONFIG['local_epochs']}\")\n",
    "    print(f\"Alpha (non-IID): {CONFIG['alpha']}\")\n",
    "    print(\"_\" * 100)\n",
    "\n",
    "    # Enable pin_memory for CUDA to speed up data transfer\n",
    "    pin_memory = (device.type == \"cuda\")\n",
    "    print(\"\\n[1/5] Loading data...\")\n",
    "    train_dataset, test_dataset = load_cifar100(CONFIG[\"data_root\"])\n",
    "    \n",
    "    # Create test loader (no shuffling needed for evaluation)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=256, \n",
    "        shuffle=False,\n",
    "        num_workers=0,  # Avoid multiprocessing fork issues\n",
    "        pin_memory=pin_memory\n",
    "    )\n",
    "\n",
    "    print(\"[2/5] Partitioning data (Dirichlet non-IID)...\")\n",
    "    client_indices = dirichlet_noniid_indices(\n",
    "        train_dataset,\n",
    "        CONFIG[\"num_clients\"],\n",
    "        CONFIG[\"alpha\"],\n",
    "    )\n",
    "\n",
    "    # Create DataLoader for each client\n",
    "    client_loaders = {}\n",
    "    for cid, indices in client_indices.items():\n",
    "        subset = Subset(train_dataset, indices)\n",
    "        \n",
    "        # Set client-specific seed for reproducibility\n",
    "        generator = torch.Generator()\n",
    "        generator.manual_seed(CONFIG[\"seed\"] + int(cid))\n",
    "        \n",
    "        client_loaders[cid] = DataLoader(\n",
    "            subset,\n",
    "            batch_size=CONFIG[\"local_batch_size\"],\n",
    "            shuffle=True,\n",
    "            num_workers=0,  # Avoid fork issues\n",
    "            worker_init_fn=seed_worker,\n",
    "            generator=generator,\n",
    "            pin_memory=pin_memory,\n",
    "        )\n",
    "\n",
    "    print(f\"   Client data sizes: {[len(idx) for idx in client_indices.values()]}\")\n",
    "    print(\"[3/5] Building model...\")\n",
    "    global_model = build_model(CONFIG[\"num_classes\"]).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Configure optimizer\n",
    "    opt_cfg = OptimCfg(\n",
    "        name=CONFIG[\"optimizer\"],\n",
    "        lr=CONFIG[\"learning_rate\"],\n",
    "        momentum=CONFIG[\"momentum\"],\n",
    "        weight_decay=CONFIG[\"weight_decay\"],\n",
    "    )\n",
    "\n",
    "    # Create experiment directory\n",
    "    experiment_dir = Path(CONFIG[\"artifact_root\"]) / CONFIG[\"experiment_name\"]\n",
    "    ensure_dir(experiment_dir)\n",
    "    \n",
    "    # PRIVACY: Initialize Differential Privacy Accountant (use client sampling rate; one step per round)\n",
    "    if CONFIG.get(\"enable_dp\", False):\n",
    "        from privacy_accountant import SimpleRDPAccountant\n",
    "        client_sample_rate = CONFIG[\"clients_per_round\"] / CONFIG[\"num_clients\"]\n",
    "        accountant = SimpleRDPAccountant(\n",
    "            noise_multiplier=CONFIG.get(\"noise_multiplier\", 1.0),\n",
    "            sample_rate=client_sample_rate,\n",
    "            target_delta=CONFIG.get(\"target_delta\", 1e-5)\n",
    "        )\n",
    "        print(f\"DP enabled: noise={CONFIG['noise_multiplier']}, clip={CONFIG['clip_norm']}\")\n",
    "    else:\n",
    "        accountant = None\n",
    "        print(\"DP disabled\")\n",
    "    \n",
    "    # Save experiment configuration\n",
    "    if CONFIG.get(\"persist_config_snapshot\", True):\n",
    "        config_snapshot = dict(CONFIG)\n",
    "        config_snapshot.update({\n",
    "            \"resolved_device\": str(device),\n",
    "            \"param_meta\": param_order_and_shapes(global_model),\n",
    "        })\n",
    "        with open(experiment_dir / \"experiment_config.json\", \"w\") as f:\n",
    "            json.dump(config_snapshot, f, indent=2, default=json_default)\n",
    "    \n",
    "    # ENCRYPTION: Initialize Selective Encryption Adapter\n",
    "    if CONFIG.get(\"enable_encryption\", False):\n",
    "        from encryption_adapter import SelectiveEncryptionAdapter\n",
    "        encryption_adapter = SelectiveEncryptionAdapter(\n",
    "            layers_to_encrypt=CONFIG[\"layers_to_encrypt\"]\n",
    "        )\n",
    "        print(f\"Encryption enabled for layers: {CONFIG['layers_to_encrypt']}\")\n",
    "    else:\n",
    "        encryption_adapter = None\n",
    "\n",
    "    print(\"[4/5] Starting federated training...\")\n",
    "    \n",
    "    for round_num in range(CONFIG[\"num_rounds\"]):\n",
    "        print(f\"\\n--- Round {round_num + 1}/{CONFIG['num_rounds']} ---\")\n",
    "\n",
    "        # Sample participating clients for this round\n",
    "        participating = random.sample(\n",
    "            list(client_loaders.keys()),\n",
    "            CONFIG[\"clients_per_round\"],\n",
    "        )\n",
    "        selected_loaders = {cid: client_loaders[cid] for cid in participating}\n",
    "\n",
    "        round_start = time.perf_counter()\n",
    "        client_artifact_paths = {}\n",
    "\n",
    "        # CALLBACK: Define function to save client updates\n",
    "        client_callback = None\n",
    "        if CONFIG.get(\"persist_client_payloads\", True):\n",
    "            def _callback(r_idx, client_id, result, global_state):\n",
    "                \"\"\"Save client update to disk\"\"\"\n",
    "                tele = result[\"telemetry\"]\n",
    "                \n",
    "                # Determine client seed\n",
    "                seed_value = None\n",
    "                if client_seeds and client_id in client_seeds:\n",
    "                    seed_value = client_seeds[client_id]\n",
    "                elif CONFIG.get(\"seed\") is not None:\n",
    "                    seed_value = CONFIG[\"seed\"] + int(client_id)\n",
    "                \n",
    "                # Package metadata\n",
    "                extra_meta = {\n",
    "                    \"seed\": seed_value,\n",
    "                    \"num_samples\": int(tele[\"num_samples\"]),\n",
    "                    \"num_batches\": len(tele[\"batch_sizes\"]),\n",
    "                    \"batch_sizes\": [int(b) for b in tele[\"batch_sizes\"]],\n",
    "                    \"gradient_norm\": tele[\"gradient_norm\"],\n",
    "                    \"num_steps_captured\": tele.get(\"num_steps_captured\"),\n",
    "                }\n",
    "                if tele.get(\"class_distribution\") is not None:\n",
    "                    extra_meta[\"class_distribution\"] = tele[\"class_distribution\"]\n",
    "                if tele.get(\"loss_history\"):\n",
    "                    extra_meta[\"loss_history\"] = tele[\"loss_history\"]\n",
    "                \n",
    "                # Save to disk\n",
    "                path = save_client_update(\n",
    "                    experiment_dir=experiment_dir,\n",
    "                    round_idx=r_idx,\n",
    "                    client_id=client_id,\n",
    "                    global_state=global_state,\n",
    "                    local_state=result[\"local_state_after\"],\n",
    "                    shard_size=tele[\"num_samples\"],\n",
    "                    lr=opt_cfg.lr,\n",
    "                    epochs=CONFIG[\"local_epochs\"],\n",
    "                    extra_meta=extra_meta,\n",
    "                )\n",
    "                client_artifact_paths[int(client_id)] = str(path.relative_to(experiment_dir))\n",
    "\n",
    "            client_callback = _callback\n",
    "\n",
    "        # Generate seeds for this round\n",
    "        server_seed = CONFIG[\"seed\"] + round_num if CONFIG.get(\"seed\") is not None else None\n",
    "        client_seeds = {cid: CONFIG[\"seed\"] + round_num + int(cid) for cid in participating} if CONFIG.get(\"seed\") is not None else None\n",
    "\n",
    "        # RUN ONE FEDERATED ROUND\n",
    "        metrics = run_fed_round_with_capture(\n",
    "            round_num=round_num,\n",
    "            global_model=global_model,\n",
    "            clients=selected_loaders,\n",
    "            loss_fn=loss_fn,\n",
    "            opt_cfg=opt_cfg,\n",
    "            local_epochs=CONFIG[\"local_epochs\"],\n",
    "            device=device,\n",
    "            num_classes=CONFIG[\"num_classes\"],\n",
    "            max_steps_to_store=CONFIG[\"max_steps_to_store\"],\n",
    "            return_indices=CONFIG[\"return_indices\"],\n",
    "            server_seed=server_seed,\n",
    "            client_seeds=client_seeds,\n",
    "            training_meta={\"dataset\": CONFIG[\"dataset\"], \"alpha\": CONFIG[\"alpha\"]},\n",
    "            global_eval_fn=lambda m: evaluate(m, test_loader, device),\n",
    "            clip_norm=CONFIG.get(\"clip_norm\"),              # Pass gradient clipping\n",
    "            encryption_adapter=encryption_adapter,          # Pass encryption adapter\n",
    "            client_callback=client_callback,\n",
    "        )\n",
    "\n",
    "        # Record timing\n",
    "        metrics[\"round_wall_time_sec\"] = time.perf_counter() - round_start\n",
    "        metrics[\"client_artifacts\"] = client_artifact_paths\n",
    "\n",
    "        # Add artifact paths to client metrics\n",
    "        if client_artifact_paths:\n",
    "            for cid, path in client_artifact_paths.items():\n",
    "                if cid in metrics[\"client_metrics\"]:\n",
    "                    metrics[\"client_metrics\"][cid][\"artifact_path\"] = path\n",
    "\n",
    "        # UPDATE GLOBAL MODEL\n",
    "        current_state = global_model.state_dict()\n",
    "        new_state = {}\n",
    "        for k in current_state.keys():\n",
    "            if k in metrics[\"server_aggregate_delta\"]:\n",
    "                # Apply aggregated delta: new = old + delta\n",
    "                new_state[k] = current_state[k] + metrics[\"server_aggregate_delta\"][k].to(device)\n",
    "            else:\n",
    "                new_state[k] = current_state[k]\n",
    "        global_model.load_state_dict(new_state)\n",
    "\n",
    "        # PRIVACY: Update privacy budget (one composition step per round)\n",
    "        if accountant:\n",
    "            accountant.step(num_steps=1)\n",
    "            privacy_spent = accountant.get_privacy_spent()\n",
    "            print(f\"   Privacy: Îµ={privacy_spent['epsilon']:.2f}, Î´={privacy_spent['delta']:.2e}\")\n",
    "\n",
    "        # DISPLAY ROUND RESULTS\n",
    "        print(f\"   Clients: {participating}\")\n",
    "        print(f\"   Global Loss: {metrics['global_loss']:.4f}\" if metrics['global_loss'] is not None else \"   Global Loss: n/a\")\n",
    "        print(f\"   Global Acc: {metrics['global_accuracy']:.4f}\" if metrics['global_accuracy'] is not None else \"   Global Acc: n/a\")\n",
    "        \n",
    "        upload_mb = metrics[\"communication_bytes\"][\"client_upload_total\"] / 1e6 if metrics[\"communication_bytes\"][\"client_upload_total\"] else 0.0\n",
    "        print(f\"   Round time: {metrics['round_wall_time_sec']:.2f}s | Client upload: {upload_mb:.2f} MB\")\n",
    "\n",
    "        # SAVE ROUND METRICS\n",
    "        export_paths = save_round_export(\n",
    "            metrics,\n",
    "            experiment_dir=experiment_dir,\n",
    "            prefix=CONFIG[\"save_prefix\"],\n",
    "            persist_json=CONFIG.get(\"persist_round_metrics\", True),\n",
    "        )\n",
    "\n",
    "        # Helper function to convert paths to relative\n",
    "        def _rel(path_str):\n",
    "            if path_str is None:\n",
    "                return None\n",
    "            p = Path(path_str)\n",
    "            try:\n",
    "                return str(p.relative_to(experiment_dir))\n",
    "            except ValueError:\n",
    "                return str(p)\n",
    "\n",
    "        metrics[\"round_artifacts\"] = {\n",
    "            \"round_dir\": _rel(export_paths[\"round_dir\"]),\n",
    "            \"tensor\": _rel(export_paths[\"tensor_path\"]),\n",
    "            \"meta\": _rel(export_paths.get(\"meta_path\")),\n",
    "        }\n",
    "        print(f\"   Saved artifacts under {metrics['round_artifacts']['round_dir']}\")\n",
    "\n",
    "    print(\"\\n[5/5] Final evaluation...\")\n",
    "    final_loss, final_acc = evaluate(global_model, test_loader, device)\n",
    "    print(f\"   Final Test Loss: {final_loss:.4f}\")\n",
    "    print(f\"   Final Test Accuracy: {final_acc:.4f}\")\n",
    "\n",
    "    print(\"\\n\" + \"-\" * 100)\n",
    "    print(\"Training complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl_privacy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
