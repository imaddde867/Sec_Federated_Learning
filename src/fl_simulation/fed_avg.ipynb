{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "902ce877-c796-4abd-91e0-dd5cdad766f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libs and quick parameters definition\n",
    "\n",
    "import copy\n",
    "import random\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "number_of_clients = 5\n",
    "number_of_rounds = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9418489-d662-454c-a872-e7a80b628b46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_cifar100():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(), #convert each image to a tensor\n",
    "        transforms.Normalize((0.5071, 0.4867, 0.4408),\n",
    "                             (0.2675, 0.2565, 0.2761))  # CIFAR-100 mean/std deviation\n",
    "    ])\n",
    "    train = datasets.CIFAR100(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    test = datasets.CIFAR100(root=\"./data\", train=False, download=True, transform=transform)\n",
    "    return train, test\n",
    "\n",
    "train, test = load_cifar100()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3cbcb6f-1e17-448e-98fc-083c0621dd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10000, 10000, 10000, 10000, 10000]\n"
     ]
    }
   ],
   "source": [
    "# Next we try to simulate multiple clients in FL, each with a portion of the dataset\n",
    "def partition_dataset(dataset, num_clients, iid=True): # Defaults to independent & identically distributed\n",
    "    n = len(dataset)\n",
    "    indices = list(range(n))\n",
    "    if iid: # then every client gets a random, fair sample of the data\n",
    "        random.shuffle(indices)\n",
    "        split = n // num_clients\n",
    "        parts = [indices[i*split:(i+1)*split] for i in range(num_clients)]\n",
    "        # last client gets remainder\n",
    "        parts[-1].extend(indices[num_clients*split:])\n",
    "    else:\n",
    "        # non-iid: group by class (simple approach) - could add later ?\n",
    "        raise NotImplementedError(\"Non-iid partition not implemented yet\")\n",
    "    return parts # Returns a list of lists, where each inner list contains dataset indices belonging to one client.\n",
    "\n",
    "parts = partition_dataset(train, number_of_clients) # 4 for 4 clients\n",
    "print([len(p) for p in parts])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38bacbff-3f37-4844-87b9-b4ae83e1d670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1/3 finished.\n",
      "Round 2/3 finished.\n",
      "Round 3/3 finished.\n",
      "Global test acc: 0.1712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def local_train(model, dataset, device, epochs=1, batch_size=32, lr=0.01):\n",
    "    model = copy.deepcopy(model) # each client gets its own copy of the global model\n",
    "    model.to(device)\n",
    "    model.train() # Train it on its local partition of the dataset\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    for _ in range(epochs):\n",
    "        for x,y in loader:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            opt.zero_grad()\n",
    "            out = model(x)\n",
    "            loss = loss_fn(out, y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "    return model.state_dict() \n",
    "    # Then after training we return only the trained weights : state_dict\n",
    "\n",
    "# FedAvg algorithm\n",
    "def average_weights(weight_list):\n",
    "    avg = copy.deepcopy(weight_list[0])\n",
    "    for k in avg.keys():\n",
    "        # for each parameter, it computes the element-wise mean across all clients\n",
    "        for i in range(1, len(weight_list)):\n",
    "            avg[k] += weight_list[i][k]\n",
    "        avg[k] = torch.div(avg[k], len(weight_list))\n",
    "    return avg # Returns the averaged model weights.\n",
    "\n",
    "def federated_training(num_clients=4, rounds=10, local_epochs=1, device=\"mps\"): # mps for apple Metal series gpu, switch to cuda or cpu if otherwise\n",
    "    global_model = models.resnet18(num_classes=100) # to initialize a global Initializes a global ResNet18 model\n",
    "    global_state = global_model.state_dict()\n",
    "\n",
    "    for r in range(rounds): # Each round = 1 global communication cycle \n",
    "        selected = list(range(num_clients))  # simple: all clients\n",
    "        client_states = []\n",
    "        for c in selected:\n",
    "            client_dataset = Subset(train, parts[c])\n",
    "            local_state = local_train(global_model, client_dataset, device,\n",
    "                                      epochs=local_epochs, batch_size=64, lr=0.01)\n",
    "            # All clients download the global model\n",
    "            # Each client trains locally on its partition for n local_epochs and produces new weights\n",
    "            # server collects all local weights\n",
    "            client_states.append(local_state)\n",
    "        # FedAvg\n",
    "        averaged = average_weights(client_states)\n",
    "            # Server averages them\n",
    "        global_model.load_state_dict(averaged)\n",
    "            # The average model becomes the new global one for the next round\n",
    "        print(f\"Round {r+1}/{rounds} finished.\")\n",
    "\n",
    "    # evaluate global model against global test set\n",
    "    global_model.to(device)\n",
    "    global_model.eval()\n",
    "    # test accuracy results:\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loader = DataLoader(test, batch_size=128)\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            out = global_model(x)\n",
    "            pred = out.argmax(dim=1)\n",
    "            correct += (pred==y).sum().item()\n",
    "            total += y.size(0)\n",
    "    print(\"Global test acc:\", correct/total)\n",
    "    return global_model\n",
    "\n",
    "federated_training(num_clients=number_of_clients, rounds=number_of_rounds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
