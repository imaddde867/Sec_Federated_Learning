{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "426f71b6-ed5c-47f9-9a35-f84920d83a5e",
   "metadata": {},
   "source": [
    "# Federated Averaging (FedAvg) baseline on CIFAR-100\n",
    "- Dirichlet non-IID partitioning\n",
    "- Partial client participation\n",
    "- Optional heterogeneity (per-client batch size / epochs / lr)\n",
    "## Imports and simulation defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb67608-4ff3-48de-a18c-c521e3ed9f04",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "# Reproducibility\n",
    "rng_seed = 42\n",
    "random.seed(rng_seed)\n",
    "np.random.seed(rng_seed)\n",
    "torch.manual_seed(rng_seed)  \n",
    "# (we can also seed CUDA later if present: torch.cuda.manual_seed_all(rng_seed))\n",
    "\n",
    "# Device helper (prefers CUDA, then MPS, else CPU)\n",
    "def get_device(prefer: Optional[str] = None) -> torch.device:\n",
    "    if prefer == \"cuda\" and torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    if prefer == \"mps\" and getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    if getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    return torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640693cd-8558-4039-94a6-73e1c7310bb8",
   "metadata": {},
   "source": [
    "### Data: CIFAR-100 loaders (train/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4d32ec-704c-495b-8df7-aae896d1af55",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def load_cifar100(data_root: str = \"./data\"):\n",
    "    # Mild augmentation on train; standard normalization\n",
    "    mean = (0.5071, 0.4867, 0.4408)\n",
    "    std = (0.2675, 0.2565, 0.2761)\n",
    "\n",
    "    train_tf = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ])\n",
    "    test_tf = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ])\n",
    "\n",
    "    train = datasets.CIFAR100(root=data_root, train=True, download=True, transform=train_tf)\n",
    "    test = datasets.CIFAR100(root=data_root, train=False, download=True, transform=test_tf)\n",
    "    return train, test  # mirrors your original intent. \n",
    "\n",
    "\n",
    "# %%\n",
    "# Targets accessor (handles .targets/.labels)\n",
    "def _get_targets(dataset) -> np.ndarray:\n",
    "    targets = getattr(dataset, \"targets\", None)\n",
    "    if targets is None:\n",
    "        targets = getattr(dataset, \"labels\", None)\n",
    "    if targets is None:\n",
    "        raise AttributeError(\"Dataset has no 'targets' or 'labels'.\")\n",
    "    return np.array(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f347b8f-a81e-4fbb-a9a2-5618ed7d6fbd",
   "metadata": {},
   "source": [
    "## Dirichlet non-IID split (returns dict: client_id -> list of indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02627af-60ba-44f7-bf5f-00cd33ebb247",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def dirichlet_noniid_indices(dataset, num_clients: int, alpha: float, min_per_client: int = 10) -> Dict[int, List[int]]:\n",
    "    y = _get_targets(dataset)\n",
    "    num_classes = int(y.max()) + 1\n",
    "    idx_by_class = {c: np.where(y == c)[0] for c in range(num_classes)}\n",
    "    for c in idx_by_class:\n",
    "        np.random.shuffle(idx_by_class[c])\n",
    "\n",
    "    # Each class's indices are split among clients with Dirichlet(alpha)\n",
    "    client_indices = [[] for _ in range(num_clients)]\n",
    "    for c in range(num_classes):\n",
    "        idx_c = idx_by_class[c]\n",
    "        if len(idx_c) == 0:\n",
    "            continue\n",
    "        # Dirichlet draw for this class across clients\n",
    "        p = np.random.dirichlet([alpha] * num_clients)\n",
    "        # Proportions -> integer split (rounding by cumulative sums)\n",
    "        cuts = (np.cumsum(p) * len(idx_c)).astype(int)[:-1]\n",
    "        split = np.split(idx_c, cuts)\n",
    "        for i, shard in enumerate(split):\n",
    "            client_indices[i].extend(shard.tolist())\n",
    "\n",
    "    # Ensure minimum per client (fallback to random fill if some are tiny)\n",
    "    # This usually isn't necessary for reasonable alpha, but keeps loaders happy\n",
    "    pool = list(range(len(dataset)))\n",
    "    for i in range(num_clients):\n",
    "        if len(client_indices[i]) < min_per_client:\n",
    "            need = min_per_client - len(client_indices[i])\n",
    "            extra = np.random.choice(pool, size=need, replace=False).tolist()\n",
    "            client_indices[i].extend(extra)\n",
    "\n",
    "    # Shuffle each client's order (nicer batching)\n",
    "    for i in range(num_clients):\n",
    "        random.shuffle(client_indices[i])\n",
    "    return {i: client_indices[i] for i in range(num_clients)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1ab77a-7051-4c8a-a378-17572b213790",
   "metadata": {},
   "source": [
    "## Model: ResNet18 head for CIFAR-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b48ab7-a3ea-4203-b42d-de354332bd64",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def build_model(num_classes: int = 100) -> nn.Module:\n",
    "    model = models.resnet18(weights=None)  # no pretrained to avoid download in restricted envs\n",
    "    # CIFAR images are 3x32x32; torchvision ResNet expects 224x224,\n",
    "    # but it's fineâ€”ResNet is fully conv except FC. It still works on 32x32.\n",
    "    # Replace final FC layer to match number of classes\n",
    "    in_feats = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_feats, num_classes)\n",
    "    return model\n",
    "\n",
    "\n",
    "# %%\n",
    "def evaluate(model: nn.Module, loader: DataLoader, device: torch.device) -> Tuple[float, float]:\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss_sum = 0.0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            loss_sum += loss.item() * x.size(0)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += x.size(0)\n",
    "    avg_loss = loss_sum / max(1, total)\n",
    "    acc = correct / max(1, total)\n",
    "    return avg_loss, acc\n",
    "\n",
    "\n",
    "# %%\n",
    "def local_train(\n",
    "    global_model: nn.Module,\n",
    "    subset: Subset,\n",
    "    device: torch.device,\n",
    "    epochs: int = 1,\n",
    "    batch_size: int = 64,\n",
    "    lr: float = 0.01,\n",
    ") -> Dict[str, torch.Tensor]:\n",
    "    model = copy.deepcopy(global_model).to(device)\n",
    "    loader = DataLoader(subset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=False)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "    model.train()\n",
    "    for _ in range(max(1, epochs)):\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Return CPU weights to simulate uplink\n",
    "    return {k: v.detach().cpu() for k, v in model.state_dict().items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b2afc1-e8b4-4d9f-ba4f-0ade607afdfb",
   "metadata": {},
   "source": [
    "## Weighted model averaging (FedAvg) with checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2643eeb-173f-4794-a397-040687ca1ab6",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def average_weights(weight_list, sizes):\n",
    "    if not weight_list:\n",
    "        raise ValueError(\"No client weights provided.\")\n",
    "    if len(weight_list) != len(sizes):\n",
    "        raise ValueError(\"weights and sizes mismatch\")\n",
    "    total = float(sum(sizes))\n",
    "    avg = {k: torch.zeros_like(v) for k, v in weight_list[0].items()}\n",
    "\n",
    "    for wi, si in zip(weight_list, sizes):\n",
    "        w = si / total\n",
    "        for k in avg.keys():\n",
    "            if avg[k].dtype.is_floating_point:      \n",
    "                avg[k] += wi[k].float() * w\n",
    "            else:\n",
    "                avg[k] = wi[k].clone()              \n",
    "\n",
    "    return avg # mirrors safety we intend. :contentReference[oaicite:2]{index=2}\n",
    "\n",
    "# %%\n",
    "def federated_training(\n",
    "    train_dataset,\n",
    "    test_dataset,\n",
    "    partitions: Dict[int, List[int]],\n",
    "    rounds: int = 10,\n",
    "    local_epochs: int = 1,\n",
    "    device: str = \"cpu\",\n",
    "    q: float = 1.0,  # participation rate per round\n",
    "    num_classes: int = 100,\n",
    "    batch_size: int = 64,\n",
    "    lr: float = 0.01,\n",
    "    hetero_profiles: Optional[Dict[int, Dict[str, float]]] = None,  # per-client overrides\n",
    "):\n",
    "    \"\"\"\n",
    "    Train the global model using FedAvg over 'rounds' communication rounds.\n",
    "    \"\"\"\n",
    "    # Validate partitions\n",
    "    num_clients = len(partitions)\n",
    "    if num_clients == 0:\n",
    "        raise ValueError(\"No clients available for federated training.\")\n",
    "    device = get_device(device)\n",
    "\n",
    "    # Build global model\n",
    "    global_model = build_model(num_classes=num_classes).to(device)\n",
    "\n",
    "    # Test loader (global test set)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=2)\n",
    "\n",
    "    history = {\"round\": [], \"test_loss\": [], \"test_acc\": [], \"selected\": []}\n",
    "\n",
    "    for r in range(1, rounds + 1):\n",
    "        # Client sampling\n",
    "        m = max(1, int(math.ceil(q * num_clients)))\n",
    "        selected = sorted(random.sample(range(num_clients), m))\n",
    "\n",
    "        # Local updates\n",
    "        local_weights = []\n",
    "        local_sizes = []\n",
    "        for cid in selected:\n",
    "            idxs = partitions[cid]\n",
    "            subset = Subset(train_dataset, idxs)\n",
    "\n",
    "            # Per-client heterogeneity overrides if provided\n",
    "            ep = local_epochs\n",
    "            bs = batch_size\n",
    "            lr_i = lr\n",
    "            if hetero_profiles and cid in hetero_profiles:\n",
    "                ep = int(hetero_profiles[cid].get(\"epochs\", ep))\n",
    "                bs = int(hetero_profiles[cid].get(\"batch_size\", bs))\n",
    "                lr_i = float(hetero_profiles[cid].get(\"lr\", lr_i))\n",
    "\n",
    "            wi = local_train(global_model, subset, device, epochs=ep, batch_size=bs, lr=lr_i)\n",
    "            local_weights.append(wi)\n",
    "            local_sizes.append(len(subset))\n",
    "\n",
    "        # FedAvg\n",
    "        new_state = average_weights(local_weights, local_sizes)\n",
    "        global_model.load_state_dict(new_state)\n",
    "\n",
    "        # Evaluate global model\n",
    "        test_loss, test_acc = evaluate(global_model, test_loader, device)\n",
    "        history[\"round\"].append(r)\n",
    "        history[\"test_loss\"].append(test_loss)\n",
    "        history[\"test_acc\"].append(test_acc)\n",
    "        history[\"selected\"].append(selected)\n",
    "\n",
    "        print(f\"[Round {r:03d}] Test loss: {test_loss:.4f} | Test acc: {test_acc*100:.2f}% | Clients: {selected}\")\n",
    "\n",
    "    return global_model, history  # same signature goal you had. :contentReference[oaicite:3]{index=3}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb72276a-9d1b-47fe-8d8d-014832f70ea4",
   "metadata": {},
   "source": [
    "## Final "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e155dac-a8ee-45c5-bd73-f1a63236d331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Round 001] Test loss: 4.7050 | Test acc: 1.00% | Clients: [0, 2, 3, 4, 5, 6, 7, 9]\n",
      "[Round 002] Test loss: 4.5497 | Test acc: 1.52% | Clients: [0, 2, 3, 4, 5, 6, 7, 9]\n",
      "[Round 003] Test loss: 4.1629 | Test acc: 5.92% | Clients: [0, 1, 3, 4, 5, 6, 8, 9]\n",
      "[Round 004] Test loss: 3.8902 | Test acc: 9.79% | Clients: [1, 2, 4, 5, 6, 7, 8, 9]\n",
      "[Round 005] Test loss: 3.6892 | Test acc: 13.83% | Clients: [1, 2, 3, 4, 5, 7, 8, 9]\n",
      "[Round 006] Test loss: 3.5107 | Test acc: 17.14% | Clients: [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "[Round 007] Test loss: 3.4494 | Test acc: 18.49% | Clients: [1, 2, 3, 4, 5, 6, 7, 8]\n",
      "[Round 008] Test loss: 3.3218 | Test acc: 20.47% | Clients: [0, 1, 3, 4, 5, 7, 8, 9]\n",
      "[Round 009] Test loss: 3.2474 | Test acc: 21.49% | Clients: [0, 1, 2, 4, 5, 6, 8, 9]\n",
      "[Round 010] Test loss: 3.1447 | Test acc: 23.30% | Clients: [0, 1, 3, 4, 6, 7, 8, 9]\n",
      "[Round 011] Test loss: 3.1076 | Test acc: 24.12% | Clients: [0, 1, 2, 4, 5, 6, 7, 9]\n",
      "[Round 012] Test loss: 3.0439 | Test acc: 25.74% | Clients: [0, 3, 4, 5, 6, 7, 8, 9]\n",
      "[Round 013] Test loss: 2.9839 | Test acc: 26.46% | Clients: [1, 2, 3, 4, 5, 6, 7, 9]\n",
      "[Round 014] Test loss: 2.9361 | Test acc: 27.66% | Clients: [1, 2, 3, 4, 5, 6, 7, 8]\n",
      "[Round 015] Test loss: 2.8795 | Test acc: 28.71% | Clients: [0, 3, 4, 5, 6, 7, 8, 9]\n",
      "[Round 016] Test loss: 2.8518 | Test acc: 28.69% | Clients: [0, 1, 2, 5, 6, 7, 8, 9]\n",
      "[Round 017] Test loss: 2.8104 | Test acc: 29.92% | Clients: [1, 2, 3, 4, 5, 6, 7, 8]\n",
      "[Round 018] Test loss: 2.7717 | Test acc: 30.54% | Clients: [1, 2, 3, 4, 5, 7, 8, 9]\n",
      "[Round 019] Test loss: 2.6980 | Test acc: 31.93% | Clients: [0, 1, 4, 5, 6, 7, 8, 9]\n",
      "[Round 020] Test loss: 2.6835 | Test acc: 32.23% | Clients: [0, 1, 2, 3, 4, 5, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # --- Config (kept close to your defaults) ---\n",
    "    number_of_clients = 10\n",
    "    number_of_rounds = 20\n",
    "    local_epochs = 1            # start small for smoke tests; raise later\n",
    "    participation = 0.75        # fraction of clients per round\n",
    "    dirichlet_alpha = 0.5       # non-IID strength (lower => more skew)\n",
    "    batch_size = 64\n",
    "    lr = 0.01\n",
    "    device_pref = None          # \"cuda\" | \"mps\" | \"cpu\" | None (auto)\n",
    "\n",
    "    # (These reflect the same values/types you were using.) :contentReference[oaicite:4]{index=4}\n",
    "\n",
    "    # --- Data ---\n",
    "    train_dataset, test_dataset = load_cifar100()\n",
    "\n",
    "    # --- Partitioning ---\n",
    "    partitions = dirichlet_noniid_indices(\n",
    "        train_dataset, num_clients=number_of_clients, alpha=dirichlet_alpha\n",
    "    )\n",
    "\n",
    "    # Optional: example heterogeneity profile\n",
    "    # hetero_profiles = {\n",
    "    #     0: {\"epochs\": 2, \"batch_size\": 32, \"lr\": 0.02},\n",
    "    #     3: {\"epochs\": 1, \"batch_size\": 128, \"lr\": 0.005},\n",
    "    # }\n",
    "    hetero_profiles = None\n",
    "\n",
    "    # --- Federated training ---\n",
    "    model, hist = federated_training(\n",
    "        train_dataset=train_dataset,\n",
    "        test_dataset=test_dataset,\n",
    "        partitions=partitions,\n",
    "        rounds=number_of_rounds,\n",
    "        local_epochs=local_epochs,\n",
    "        device=device_pref or \"auto\",\n",
    "        q=participation,\n",
    "        num_classes=100,\n",
    "        batch_size=batch_size,\n",
    "        lr=lr,\n",
    "        hetero_profiles=hetero_profiles,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5546f63b",
   "metadata": {},
   "source": [
    "## Metrics to export \n",
    "\n",
    "metrics_to_export = {\n",
    "    'round': round_num,\n",
    "    'participating_clients': client_ids,\n",
    "    \n",
    "    # Per-client exports\n",
    "    'client_metrics': {\n",
    "        client_id: {\n",
    "            'gradient_norm': float,\n",
    "            'per_layer_norms': dict,\n",
    "            'batch_size': int,\n",
    "            'local_epochs': int,\n",
    "            'learning_rate': float,\n",
    "            'num_samples': int,\n",
    "            'class_distribution': dict,\n",
    "            'local_loss': float,\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # Global state\n",
    "    'global_model_state': state_dict,  # or checkpoint path\n",
    "    'global_accuracy': float,\n",
    "    'global_loss': float,\n",
    "    \n",
    "    # For reconstruction\n",
    "    'raw_gradients': {client_id: gradient_dict},  # KEY for breaching\n",
    "    'model_updates': {client_id: update_dict},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ae2263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# reconstruct final state and global metrics\n",
    "global_loss, global_acc = evaluate(model, DataLoader(test_dataset, batch_size=256, shuffle=False), get_device())\n",
    "\n",
    "# container for metrics\n",
    "metrics_to_export = {\n",
    "    \"round\": number_of_rounds,\n",
    "    \"participating_clients\": hist[\"selected\"][-1],\n",
    "    \"client_metrics\": {},\n",
    "    \"global_model_state\": copy.deepcopy(model.state_dict()),  # could also save to disk\n",
    "    \"global_accuracy\": float(global_acc),\n",
    "    \"global_loss\": float(global_loss),\n",
    "    \"raw_gradients\": {},\n",
    "    \"model_updates\": {},\n",
    "}\n",
    "\n",
    "# --- compute per-client metrics on the final round participants ---\n",
    "device = get_device()\n",
    "global_state = copy.deepcopy(model.state_dict())\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for cid in hist[\"selected\"][-1]:\n",
    "    idxs = partitions[cid]\n",
    "    subset = Subset(train_dataset, idxs)\n",
    "    loader = DataLoader(subset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "    # clone model to compute client gradients from final global weights\n",
    "    client_model = build_model(num_classes=100).to(device)\n",
    "    client_model.load_state_dict(global_state)\n",
    "    client_model.train()\n",
    "\n",
    "    optimizer = torch.optim.SGD(client_model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "    # one batch to approximate gradient norm\n",
    "    x, y = next(iter(loader))\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    logits = client_model(x)\n",
    "    loss = criterion(logits, y)\n",
    "    loss.backward()\n",
    "\n",
    "    grad_dict = {n: p.grad.detach().cpu().clone() for n, p in client_model.named_parameters() if p.grad is not None}\n",
    "    grad_norm = torch.sqrt(sum(torch.norm(g)**2 for g in grad_dict.values())).item()\n",
    "    per_layer_norms = {n: torch.norm(g).item() for n, g in grad_dict.items()}\n",
    "\n",
    "    # simulate a local update (1 epoch) to get model delta\n",
    "    local_weights = local_train(model, subset, device, epochs=1, batch_size=batch_size, lr=lr)\n",
    "    update_dict = {\n",
    "    k: local_weights[k].cpu() - global_state[k].detach().cpu()\n",
    "    for k in global_state.keys()\n",
    "    }\n",
    "    # class distribution for this client\n",
    "    y_subset = [train_dataset.targets[i] for i in idxs]\n",
    "    class_counts = dict(zip(*np.unique(y_subset, return_counts=True)))\n",
    "\n",
    "    metrics_to_export[\"client_metrics\"][cid] = {\n",
    "        \"gradient_norm\": float(grad_norm),\n",
    "        \"per_layer_norms\": per_layer_norms,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"local_epochs\": local_epochs,\n",
    "        \"learning_rate\": lr,\n",
    "        \"num_samples\": len(subset),\n",
    "        \"class_distribution\": class_counts,\n",
    "        \"local_loss\": float(loss.item()),\n",
    "    }\n",
    "    metrics_to_export[\"raw_gradients\"][cid] = grad_dict\n",
    "    metrics_to_export[\"model_updates\"][cid] = update_dict\n",
    "\n",
    "print(\"Metrics extracted for\", len(metrics_to_export[\"client_metrics\"]), \"clients.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bdaba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global accuracy: 0.3223\n",
      "Global loss: 2.683524996185303\n",
      "Round: 20\n",
      "Clients: [0, 1, 2, 3, 4, 5, 7, 9]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(\"Global accuracy:\", metrics_to_export[\"global_accuracy\"])\n",
    "print(\"Global loss:\", metrics_to_export[\"global_loss\"])\n",
    "print(\"Round:\", metrics_to_export[\"round\"])\n",
    "print(\"Clients:\", metrics_to_export[\"participating_clients\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1212fd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Client 0:\n",
      "  samples = 4860\n",
      "  local_loss = 3.2197\n",
      "  grad_norm = 5.99\n",
      "  top-3 per-layer norms = [('conv1.weight', 1.4087834358215332), ('bn1.weight', 0.12101278454065323), ('bn1.bias', 0.06460622698068619)]\n",
      "\n",
      "Client 1:\n",
      "  samples = 5014\n",
      "  local_loss = 2.4702\n",
      "  grad_norm = 4.61\n",
      "  top-3 per-layer norms = [('conv1.weight', 0.9140346050262451), ('bn1.weight', 0.10412313789129257), ('bn1.bias', 0.05682973563671112)]\n",
      "\n",
      "Client 2:\n",
      "  samples = 5582\n",
      "  local_loss = 2.8508\n",
      "  grad_norm = 5.30\n",
      "  top-3 per-layer norms = [('conv1.weight', 1.2020173072814941), ('bn1.weight', 0.11466034501791), ('bn1.bias', 0.07469813525676727)]\n",
      "\n",
      "Client 3:\n",
      "  samples = 4299\n",
      "  local_loss = 2.4702\n",
      "  grad_norm = 5.40\n",
      "  top-3 per-layer norms = [('conv1.weight', 1.3166335821151733), ('bn1.weight', 0.10946671664714813), ('bn1.bias', 0.0636722594499588)]\n",
      "\n",
      "Client 4:\n",
      "  samples = 4640\n",
      "  local_loss = 2.5860\n",
      "  grad_norm = 5.30\n",
      "  top-3 per-layer norms = [('conv1.weight', 1.2379850149154663), ('bn1.weight', 0.11968004703521729), ('bn1.bias', 0.061828501522541046)]\n",
      "\n",
      "Client 5:\n",
      "  samples = 5622\n",
      "  local_loss = 2.5224\n",
      "  grad_norm = 4.98\n",
      "  top-3 per-layer norms = [('conv1.weight', 1.180086612701416), ('bn1.weight', 0.13401862978935242), ('bn1.bias', 0.057792630046606064)]\n",
      "\n",
      "Client 7:\n",
      "  samples = 4753\n",
      "  local_loss = 2.6995\n",
      "  grad_norm = 5.58\n",
      "  top-3 per-layer norms = [('conv1.weight', 1.4191551208496094), ('bn1.weight', 0.125900536775589), ('bn1.bias', 0.07413087040185928)]\n",
      "\n",
      "Client 9:\n",
      "  samples = 4966\n",
      "  local_loss = 2.7888\n",
      "  grad_norm = 5.47\n",
      "  top-3 per-layer norms = [('conv1.weight', 1.2433061599731445), ('bn1.weight', 0.1092570349574089), ('bn1.bias', 0.07051468640565872)]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for cid, info in metrics_to_export[\"client_metrics\"].items():\n",
    "    print(f\"\\nClient {cid}:\")\n",
    "    print(f\"  samples = {info['num_samples']}\")\n",
    "    print(f\"  local_loss = {info['local_loss']:.4f}\")\n",
    "    print(f\"  grad_norm = {info['gradient_norm']:.2f}\")\n",
    "    print(f\"  top-3 per-layer norms = {list(info['per_layer_norms'].items())[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53771e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'batch_size': 64,\n",
      "     'class_distribution': {np.int64(0): np.int64(5),\n",
      "                            np.int64(1): np.int64(160),\n",
      "                            np.int64(3): np.int64(50),\n",
      "                            np.int64(4): np.int64(21),\n",
      "                            np.int64(5): np.int64(78),\n",
      "                            np.int64(6): np.int64(90),\n",
      "                            np.int64(7): np.int64(267),\n",
      "                            np.int64(8): np.int64(29),\n",
      "                            np.int64(9): np.int64(26),\n",
      "                            np.int64(10): np.int64(96),\n",
      "                            np.int64(11): np.int64(74),\n",
      "                            np.int64(12): np.int64(24),\n",
      "                            np.int64(13): np.int64(56),\n",
      "                            np.int64(14): np.int64(50),\n",
      "                            np.int64(15): np.int64(3),\n",
      "                            np.int64(16): np.int64(27),\n",
      "                            np.int64(17): np.int64(57),\n",
      "                            np.int64(18): np.int64(11),\n",
      "                            np.int64(19): np.int64(163),\n",
      "                            np.int64(20): np.int64(31),\n",
      "                            np.int64(21): np.int64(7),\n",
      "                            np.int64(22): np.int64(15),\n",
      "                            np.int64(23): np.int64(16),\n",
      "                            np.int64(24): np.int64(73),\n",
      "                            np.int64(25): np.int64(60),\n",
      "                            np.int64(27): np.int64(63),\n",
      "                            np.int64(29): np.int64(19),\n",
      "                            np.int64(32): np.int64(5),\n",
      "                            np.int64(33): np.int64(254),\n",
      "                            np.int64(35): np.int64(38),\n",
      "                            np.int64(36): np.int64(11),\n",
      "                            np.int64(38): np.int64(171),\n",
      "                            np.int64(39): np.int64(7),\n",
      "                            np.int64(40): np.int64(79),\n",
      "                            np.int64(41): np.int64(9),\n",
      "                            np.int64(42): np.int64(103),\n",
      "                            np.int64(43): np.int64(4),\n",
      "                            np.int64(44): np.int64(51),\n",
      "                            np.int64(45): np.int64(3),\n",
      "                            np.int64(46): np.int64(9),\n",
      "                            np.int64(47): np.int64(12),\n",
      "                            np.int64(48): np.int64(20),\n",
      "                            np.int64(49): np.int64(14),\n",
      "                            np.int64(50): np.int64(4),\n",
      "                            np.int64(51): np.int64(10),\n",
      "                            np.int64(53): np.int64(1),\n",
      "                            np.int64(54): np.int64(31),\n",
      "                            np.int64(55): np.int64(11),\n",
      "                            np.int64(56): np.int64(38),\n",
      "                            np.int64(57): np.int64(2),\n",
      "                            np.int64(58): np.int64(13),\n",
      "                            np.int64(59): np.int64(83),\n",
      "                            np.int64(60): np.int64(41),\n",
      "                            np.int64(61): np.int64(11),\n",
      "                            np.int64(62): np.int64(59),\n",
      "                            np.int64(63): np.int64(60),\n",
      "                            np.int64(64): np.int64(97),\n",
      "                            np.int64(65): np.int64(19),\n",
      "                            np.int64(66): np.int64(67),\n",
      "                            np.int64(67): np.int64(4),\n",
      "                            np.int64(69): np.int64(117),\n",
      "                            np.int64(70): np.int64(137),\n",
      "                            np.int64(71): np.int64(60),\n",
      "                            np.int64(72): np.int64(6),\n",
      "                            np.int64(73): np.int64(255),\n",
      "                            np.int64(74): np.int64(170),\n",
      "                            np.int64(75): np.int64(126),\n",
      "                            np.int64(76): np.int64(3),\n",
      "                            np.int64(77): np.int64(3),\n",
      "                            np.int64(78): np.int64(58),\n",
      "                            np.int64(79): np.int64(13),\n",
      "                            np.int64(80): np.int64(56),\n",
      "                            np.int64(81): np.int64(102),\n",
      "                            np.int64(82): np.int64(90),\n",
      "                            np.int64(83): np.int64(93),\n",
      "                            np.int64(84): np.int64(81),\n",
      "                            np.int64(85): np.int64(18),\n",
      "                            np.int64(86): np.int64(169),\n",
      "                            np.int64(89): np.int64(129),\n",
      "                            np.int64(90): np.int64(31),\n",
      "                            np.int64(91): np.int64(22),\n",
      "                            np.int64(92): np.int64(8),\n",
      "                            np.int64(93): np.int64(21),\n",
      "                            np.int64(94): np.int64(6),\n",
      "                            np.int64(95): np.int64(11),\n",
      "                            np.int64(96): np.int64(105),\n",
      "                            np.int64(97): np.int64(28),\n",
      "                            np.int64(98): np.int64(9),\n",
      "                            np.int64(99): np.int64(21)},\n",
      "     'gradient_norm': 5.994349479675293,\n",
      "     'learning_rate': 0.01,\n",
      "     'local_epochs': 1,\n",
      "     'local_loss': 3.21972918510437,\n",
      "     'num_samples': 4860,\n",
      "     'per_layer_norms': {'bn1.bias': 0.06460622698068619,\n",
      "                         'bn1.weight': 0.12101278454065323,\n",
      "                         'conv1.weight': 1.4087834358215332,\n",
      "                         'fc.bias': 0.23080840706825256,\n",
      "                         'fc.weight': 3.5072641372680664,\n",
      "                         'layer1.0.bn1.bias': 0.06826669722795486,\n",
      "                         'layer1.0.bn1.weight': 0.05917563661932945,\n",
      "                         'layer1.0.bn2.bias': 0.04036187753081322,\n",
      "                         'layer1.0.bn2.weight': 0.060733675956726074,\n",
      "                         'layer1.0.conv1.weight': 1.0284156799316406,\n",
      "                         'layer1.0.conv2.weight': 0.9235405325889587,\n",
      "                         'layer1.1.bn1.bias': 0.04558330401778221,\n",
      "                         'layer1.1.bn1.weight': 0.04800955578684807,\n",
      "                         'layer1.1.bn2.bias': 0.027856063097715378,\n",
      "                         'layer1.1.bn2.weight': 0.048816945403814316,\n",
      "                         'layer1.1.conv1.weight': 0.8262929320335388,\n",
      "                         'layer1.1.conv2.weight': 0.7865390181541443,\n",
      "                         'layer2.0.bn1.bias': 0.04947930574417114,\n",
      "                         'layer2.0.bn1.weight': 0.061748284846544266,\n",
      "                         'layer2.0.bn2.bias': 0.043094899505376816,\n",
      "                         'layer2.0.bn2.weight': 0.062479689717292786,\n",
      "                         'layer2.0.conv1.weight': 1.104521632194519,\n",
      "                         'layer2.0.conv2.weight': 1.1982508897781372,\n",
      "                         'layer2.0.downsample.0.weight': 0.4782814085483551,\n",
      "                         'layer2.0.downsample.1.bias': 0.043094899505376816,\n",
      "                         'layer2.0.downsample.1.weight': 0.060719240456819534,\n",
      "                         'layer2.1.bn1.bias': 0.03828044235706329,\n",
      "                         'layer2.1.bn1.weight': 0.04871977120637894,\n",
      "                         'layer2.1.bn2.bias': 0.0336480438709259,\n",
      "                         'layer2.1.bn2.weight': 0.0439932681620121,\n",
      "                         'layer2.1.conv1.weight': 1.1474826335906982,\n",
      "                         'layer2.1.conv2.weight': 1.0844289064407349,\n",
      "                         'layer3.0.bn1.bias': 0.039815548807382584,\n",
      "                         'layer3.0.bn1.weight': 0.04914003983139992,\n",
      "                         'layer3.0.bn2.bias': 0.034693289548158646,\n",
      "                         'layer3.0.bn2.weight': 0.05081889405846596,\n",
      "                         'layer3.0.conv1.weight': 1.4760457277297974,\n",
      "                         'layer3.0.conv2.weight': 1.3517996072769165,\n",
      "                         'layer3.0.downsample.0.weight': 0.5256609320640564,\n",
      "                         'layer3.0.downsample.1.bias': 0.034693289548158646,\n",
      "                         'layer3.0.downsample.1.weight': 0.04696718603372574,\n",
      "                         'layer3.1.bn1.bias': 0.030521223321557045,\n",
      "                         'layer3.1.bn1.weight': 0.032790083438158035,\n",
      "                         'layer3.1.bn2.bias': 0.02259966731071472,\n",
      "                         'layer3.1.bn2.weight': 0.03714360296726227,\n",
      "                         'layer3.1.conv1.weight': 1.0869386196136475,\n",
      "                         'layer3.1.conv2.weight': 0.9663403630256653,\n",
      "                         'layer4.0.bn1.bias': 0.03061359003186226,\n",
      "                         'layer4.0.bn1.weight': 0.03484717011451721,\n",
      "                         'layer4.0.bn2.bias': 0.0826844573020935,\n",
      "                         'layer4.0.bn2.weight': 0.05945150554180145,\n",
      "                         'layer4.0.conv1.weight': 1.283414363861084,\n",
      "                         'layer4.0.conv2.weight': 1.2944477796554565,\n",
      "                         'layer4.0.downsample.0.weight': 0.7895920872688293,\n",
      "                         'layer4.0.downsample.1.bias': 0.0826844573020935,\n",
      "                         'layer4.0.downsample.1.weight': 0.07672882825136185,\n",
      "                         'layer4.1.bn1.bias': 0.027689380571246147,\n",
      "                         'layer4.1.bn1.weight': 0.029724156484007835,\n",
      "                         'layer4.1.bn2.bias': 0.11142197996377945,\n",
      "                         'layer4.1.bn2.weight': 0.056998591870069504,\n",
      "                         'layer4.1.conv1.weight': 1.120952844619751,\n",
      "                         'layer4.1.conv2.weight': 1.1321845054626465}},\n",
      " 1: {'batch_size': 64,\n",
      "     'class_distribution': {np.int64(0): np.int64(2),\n",
      "                            np.int64(1): np.int64(38),\n",
      "                            np.int64(2): np.int64(38),\n",
      "                            np.int64(3): np.int64(11),\n",
      "                            np.int64(6): np.int64(138),\n",
      "                            np.int64(7): np.int64(41),\n",
      "                            np.int64(8): np.int64(1),\n",
      "                            np.int64(9): np.int64(8),\n",
      "                            np.int64(10): np.int64(3),\n",
      "                            np.int64(11): np.int64(116),\n",
      "                            np.int64(12): np.int64(205),\n",
      "                            np.int64(13): np.int64(40),\n",
      "                            np.int64(14): np.int64(101),\n",
      "                            np.int64(15): np.int64(27),\n",
      "                            np.int64(16): np.int64(111),\n",
      "                            np.int64(17): np.int64(212),\n",
      "                            np.int64(18): np.int64(3),\n",
      "                            np.int64(19): np.int64(2),\n",
      "                            np.int64(20): np.int64(92),\n",
      "                            np.int64(21): np.int64(84),\n",
      "                            np.int64(22): np.int64(38),\n",
      "                            np.int64(23): np.int64(150),\n",
      "                            np.int64(24): np.int64(150),\n",
      "                            np.int64(25): np.int64(56),\n",
      "                            np.int64(26): np.int64(8),\n",
      "                            np.int64(27): np.int64(6),\n",
      "                            np.int64(28): np.int64(1),\n",
      "                            np.int64(30): np.int64(46),\n",
      "                            np.int64(31): np.int64(89),\n",
      "                            np.int64(32): np.int64(71),\n",
      "                            np.int64(33): np.int64(6),\n",
      "                            np.int64(34): np.int64(52),\n",
      "                            np.int64(35): np.int64(34),\n",
      "                            np.int64(36): np.int64(59),\n",
      "                            np.int64(37): np.int64(36),\n",
      "                            np.int64(38): np.int64(102),\n",
      "                            np.int64(39): np.int64(7),\n",
      "                            np.int64(40): np.int64(4),\n",
      "                            np.int64(41): np.int64(4),\n",
      "                            np.int64(42): np.int64(28),\n",
      "                            np.int64(43): np.int64(20),\n",
      "                            np.int64(44): np.int64(95),\n",
      "                            np.int64(45): np.int64(9),\n",
      "                            np.int64(46): np.int64(9),\n",
      "                            np.int64(47): np.int64(23),\n",
      "                            np.int64(50): np.int64(66),\n",
      "                            np.int64(51): np.int64(3),\n",
      "                            np.int64(52): np.int64(15),\n",
      "                            np.int64(53): np.int64(59),\n",
      "                            np.int64(54): np.int64(14),\n",
      "                            np.int64(55): np.int64(74),\n",
      "                            np.int64(56): np.int64(88),\n",
      "                            np.int64(57): np.int64(5),\n",
      "                            np.int64(58): np.int64(225),\n",
      "                            np.int64(59): np.int64(27),\n",
      "                            np.int64(60): np.int64(46),\n",
      "                            np.int64(61): np.int64(2),\n",
      "                            np.int64(62): np.int64(62),\n",
      "                            np.int64(63): np.int64(51),\n",
      "                            np.int64(64): np.int64(232),\n",
      "                            np.int64(65): np.int64(151),\n",
      "                            np.int64(66): np.int64(61),\n",
      "                            np.int64(68): np.int64(77),\n",
      "                            np.int64(69): np.int64(6),\n",
      "                            np.int64(70): np.int64(2),\n",
      "                            np.int64(71): np.int64(260),\n",
      "                            np.int64(72): np.int64(9),\n",
      "                            np.int64(73): np.int64(1),\n",
      "                            np.int64(74): np.int64(30),\n",
      "                            np.int64(75): np.int64(10),\n",
      "                            np.int64(76): np.int64(58),\n",
      "                            np.int64(77): np.int64(19),\n",
      "                            np.int64(78): np.int64(15),\n",
      "                            np.int64(79): np.int64(2),\n",
      "                            np.int64(80): np.int64(4),\n",
      "                            np.int64(81): np.int64(1),\n",
      "                            np.int64(83): np.int64(1),\n",
      "                            np.int64(84): np.int64(6),\n",
      "                            np.int64(85): np.int64(50),\n",
      "                            np.int64(86): np.int64(9),\n",
      "                            np.int64(87): np.int64(140),\n",
      "                            np.int64(89): np.int64(19),\n",
      "                            np.int64(90): np.int64(25),\n",
      "                            np.int64(91): np.int64(131),\n",
      "                            np.int64(92): np.int64(121),\n",
      "                            np.int64(93): np.int64(136),\n",
      "                            np.int64(94): np.int64(93),\n",
      "                            np.int64(95): np.int64(54),\n",
      "                            np.int64(96): np.int64(5),\n",
      "                            np.int64(97): np.int64(105),\n",
      "                            np.int64(98): np.int64(51),\n",
      "                            np.int64(99): np.int64(17)},\n",
      "     'gradient_norm': 4.605273246765137,\n",
      "     'learning_rate': 0.01,\n",
      "     'local_epochs': 1,\n",
      "     'local_loss': 2.470203399658203,\n",
      "     'num_samples': 5014,\n",
      "     'per_layer_norms': {'bn1.bias': 0.05682973563671112,\n",
      "                         'bn1.weight': 0.10412313789129257,\n",
      "                         'conv1.weight': 0.9140346050262451,\n",
      "                         'fc.bias': 0.14715656638145447,\n",
      "                         'fc.weight': 2.5284759998321533,\n",
      "                         'layer1.0.bn1.bias': 0.054245613515377045,\n",
      "                         'layer1.0.bn1.weight': 0.05315231904387474,\n",
      "                         'layer1.0.bn2.bias': 0.03906838223338127,\n",
      "                         'layer1.0.bn2.weight': 0.050682924687862396,\n",
      "                         'layer1.0.conv1.weight': 0.7613950967788696,\n",
      "                         'layer1.0.conv2.weight': 0.7295892834663391,\n",
      "                         'layer1.1.bn1.bias': 0.035572804510593414,\n",
      "                         'layer1.1.bn1.weight': 0.03815479576587677,\n",
      "                         'layer1.1.bn2.bias': 0.027115710079669952,\n",
      "                         'layer1.1.bn2.weight': 0.04368474334478378,\n",
      "                         'layer1.1.conv1.weight': 0.6139729619026184,\n",
      "                         'layer1.1.conv2.weight': 0.6299599409103394,\n",
      "                         'layer2.0.bn1.bias': 0.036722250282764435,\n",
      "                         'layer2.0.bn1.weight': 0.04118325188755989,\n",
      "                         'layer2.0.bn2.bias': 0.040239524096250534,\n",
      "                         'layer2.0.bn2.weight': 0.04830986633896828,\n",
      "                         'layer2.0.conv1.weight': 0.8522109389305115,\n",
      "                         'layer2.0.conv2.weight': 0.9334876537322998,\n",
      "                         'layer2.0.downsample.0.weight': 0.37955862283706665,\n",
      "                         'layer2.0.downsample.1.bias': 0.040239524096250534,\n",
      "                         'layer2.0.downsample.1.weight': 0.05184131860733032,\n",
      "                         'layer2.1.bn1.bias': 0.03597994148731232,\n",
      "                         'layer2.1.bn1.weight': 0.03783943131566048,\n",
      "                         'layer2.1.bn2.bias': 0.02881312556564808,\n",
      "                         'layer2.1.bn2.weight': 0.03309343382716179,\n",
      "                         'layer2.1.conv1.weight': 0.9002989530563354,\n",
      "                         'layer2.1.conv2.weight': 0.8290606737136841,\n",
      "                         'layer3.0.bn1.bias': 0.034446511417627335,\n",
      "                         'layer3.0.bn1.weight': 0.037686727941036224,\n",
      "                         'layer3.0.bn2.bias': 0.03106963075697422,\n",
      "                         'layer3.0.bn2.weight': 0.041658032685518265,\n",
      "                         'layer3.0.conv1.weight': 1.1661604642868042,\n",
      "                         'layer3.0.conv2.weight': 1.0701488256454468,\n",
      "                         'layer3.0.downsample.0.weight': 0.4120256304740906,\n",
      "                         'layer3.0.downsample.1.bias': 0.03106963075697422,\n",
      "                         'layer3.0.downsample.1.weight': 0.038904886692762375,\n",
      "                         'layer3.1.bn1.bias': 0.02479291521012783,\n",
      "                         'layer3.1.bn1.weight': 0.025777988135814667,\n",
      "                         'layer3.1.bn2.bias': 0.019601648673415184,\n",
      "                         'layer3.1.bn2.weight': 0.028520921245217323,\n",
      "                         'layer3.1.conv1.weight': 0.8652640581130981,\n",
      "                         'layer3.1.conv2.weight': 0.7727351188659668,\n",
      "                         'layer4.0.bn1.bias': 0.025910483673214912,\n",
      "                         'layer4.0.bn1.weight': 0.02943866327404976,\n",
      "                         'layer4.0.bn2.bias': 0.06654725223779678,\n",
      "                         'layer4.0.bn2.weight': 0.05634791776537895,\n",
      "                         'layer4.0.conv1.weight': 1.0483570098876953,\n",
      "                         'layer4.0.conv2.weight': 1.0878770351409912,\n",
      "                         'layer4.0.downsample.0.weight': 0.6930340528488159,\n",
      "                         'layer4.0.downsample.1.bias': 0.06654725223779678,\n",
      "                         'layer4.0.downsample.1.weight': 0.06590729206800461,\n",
      "                         'layer4.1.bn1.bias': 0.024040915071964264,\n",
      "                         'layer4.1.bn1.weight': 0.028649335727095604,\n",
      "                         'layer4.1.bn2.bias': 0.07746424525976181,\n",
      "                         'layer4.1.bn2.weight': 0.0522799976170063,\n",
      "                         'layer4.1.conv1.weight': 0.9713336229324341,\n",
      "                         'layer4.1.conv2.weight': 1.0110372304916382}},\n",
      " 2: {'batch_size': 64,\n",
      "     'class_distribution': {np.int64(0): np.int64(77),\n",
      "                            np.int64(1): np.int64(40),\n",
      "                            np.int64(2): np.int64(5),\n",
      "                            np.int64(3): np.int64(154),\n",
      "                            np.int64(4): np.int64(129),\n",
      "                            np.int64(5): np.int64(80),\n",
      "                            np.int64(6): np.int64(40),\n",
      "                            np.int64(7): np.int64(1),\n",
      "                            np.int64(8): np.int64(49),\n",
      "                            np.int64(9): np.int64(207),\n",
      "                            np.int64(10): np.int64(20),\n",
      "                            np.int64(11): np.int64(97),\n",
      "                            np.int64(12): np.int64(10),\n",
      "                            np.int64(13): np.int64(14),\n",
      "                            np.int64(14): np.int64(43),\n",
      "                            np.int64(15): np.int64(40),\n",
      "                            np.int64(16): np.int64(2),\n",
      "                            np.int64(17): np.int64(13),\n",
      "                            np.int64(18): np.int64(7),\n",
      "                            np.int64(19): np.int64(4),\n",
      "                            np.int64(20): np.int64(3),\n",
      "                            np.int64(21): np.int64(14),\n",
      "                            np.int64(22): np.int64(48),\n",
      "                            np.int64(23): np.int64(136),\n",
      "                            np.int64(24): np.int64(43),\n",
      "                            np.int64(25): np.int64(4),\n",
      "                            np.int64(26): np.int64(13),\n",
      "                            np.int64(27): np.int64(9),\n",
      "                            np.int64(28): np.int64(4),\n",
      "                            np.int64(29): np.int64(142),\n",
      "                            np.int64(30): np.int64(2),\n",
      "                            np.int64(31): np.int64(96),\n",
      "                            np.int64(32): np.int64(13),\n",
      "                            np.int64(33): np.int64(6),\n",
      "                            np.int64(34): np.int64(76),\n",
      "                            np.int64(35): np.int64(4),\n",
      "                            np.int64(36): np.int64(1),\n",
      "                            np.int64(37): np.int64(91),\n",
      "                            np.int64(38): np.int64(40),\n",
      "                            np.int64(39): np.int64(246),\n",
      "                            np.int64(40): np.int64(61),\n",
      "                            np.int64(41): np.int64(212),\n",
      "                            np.int64(42): np.int64(62),\n",
      "                            np.int64(43): np.int64(248),\n",
      "                            np.int64(45): np.int64(30),\n",
      "                            np.int64(46): np.int64(249),\n",
      "                            np.int64(47): np.int64(116),\n",
      "                            np.int64(48): np.int64(190),\n",
      "                            np.int64(49): np.int64(119),\n",
      "                            np.int64(52): np.int64(8),\n",
      "                            np.int64(53): np.int64(1),\n",
      "                            np.int64(55): np.int64(133),\n",
      "                            np.int64(56): np.int64(28),\n",
      "                            np.int64(57): np.int64(42),\n",
      "                            np.int64(58): np.int64(13),\n",
      "                            np.int64(59): np.int64(2),\n",
      "                            np.int64(60): np.int64(31),\n",
      "                            np.int64(61): np.int64(104),\n",
      "                            np.int64(62): np.int64(37),\n",
      "                            np.int64(63): np.int64(11),\n",
      "                            np.int64(64): np.int64(2),\n",
      "                            np.int64(65): np.int64(59),\n",
      "                            np.int64(66): np.int64(32),\n",
      "                            np.int64(67): np.int64(20),\n",
      "                            np.int64(68): np.int64(11),\n",
      "                            np.int64(69): np.int64(2),\n",
      "                            np.int64(70): np.int64(92),\n",
      "                            np.int64(71): np.int64(50),\n",
      "                            np.int64(72): np.int64(17),\n",
      "                            np.int64(73): np.int64(22),\n",
      "                            np.int64(74): np.int64(134),\n",
      "                            np.int64(75): np.int64(188),\n",
      "                            np.int64(76): np.int64(27),\n",
      "                            np.int64(77): np.int64(3),\n",
      "                            np.int64(78): np.int64(29),\n",
      "                            np.int64(79): np.int64(31),\n",
      "                            np.int64(80): np.int64(6),\n",
      "                            np.int64(81): np.int64(8),\n",
      "                            np.int64(82): np.int64(30),\n",
      "                            np.int64(83): np.int64(147),\n",
      "                            np.int64(84): np.int64(9),\n",
      "                            np.int64(85): np.int64(105),\n",
      "                            np.int64(86): np.int64(2),\n",
      "                            np.int64(87): np.int64(4),\n",
      "                            np.int64(88): np.int64(166),\n",
      "                            np.int64(89): np.int64(18),\n",
      "                            np.int64(90): np.int64(272),\n",
      "                            np.int64(91): np.int64(106),\n",
      "                            np.int64(92): np.int64(11),\n",
      "                            np.int64(93): np.int64(14),\n",
      "                            np.int64(94): np.int64(5),\n",
      "                            np.int64(95): np.int64(15),\n",
      "                            np.int64(96): np.int64(26),\n",
      "                            np.int64(97): np.int64(168),\n",
      "                            np.int64(98): np.int64(31)},\n",
      "     'gradient_norm': 5.304229259490967,\n",
      "     'learning_rate': 0.01,\n",
      "     'local_epochs': 1,\n",
      "     'local_loss': 2.85082745552063,\n",
      "     'num_samples': 5582,\n",
      "     'per_layer_norms': {'bn1.bias': 0.07469813525676727,\n",
      "                         'bn1.weight': 0.11466034501791,\n",
      "                         'conv1.weight': 1.2020173072814941,\n",
      "                         'fc.bias': 0.1603449136018753,\n",
      "                         'fc.weight': 2.6270337104797363,\n",
      "                         'layer1.0.bn1.bias': 0.06489258259534836,\n",
      "                         'layer1.0.bn1.weight': 0.07489786297082901,\n",
      "                         'layer1.0.bn2.bias': 0.03783978149294853,\n",
      "                         'layer1.0.bn2.weight': 0.069362573325634,\n",
      "                         'layer1.0.conv1.weight': 0.9834960699081421,\n",
      "                         'layer1.0.conv2.weight': 0.9218863844871521,\n",
      "                         'layer1.1.bn1.bias': 0.046708956360816956,\n",
      "                         'layer1.1.bn1.weight': 0.05375012755393982,\n",
      "                         'layer1.1.bn2.bias': 0.029611734673380852,\n",
      "                         'layer1.1.bn2.weight': 0.05662430822849274,\n",
      "                         'layer1.1.conv1.weight': 0.8220443725585938,\n",
      "                         'layer1.1.conv2.weight': 0.7582904696464539,\n",
      "                         'layer2.0.bn1.bias': 0.045944176614284515,\n",
      "                         'layer2.0.bn1.weight': 0.05285215005278587,\n",
      "                         'layer2.0.bn2.bias': 0.045588500797748566,\n",
      "                         'layer2.0.bn2.weight': 0.05677169933915138,\n",
      "                         'layer2.0.conv1.weight': 1.070898413658142,\n",
      "                         'layer2.0.conv2.weight': 1.160378098487854,\n",
      "                         'layer2.0.downsample.0.weight': 0.45334360003471375,\n",
      "                         'layer2.0.downsample.1.bias': 0.045588500797748566,\n",
      "                         'layer2.0.downsample.1.weight': 0.062140144407749176,\n",
      "                         'layer2.1.bn1.bias': 0.04209215193986893,\n",
      "                         'layer2.1.bn1.weight': 0.0512685589492321,\n",
      "                         'layer2.1.bn2.bias': 0.032716937363147736,\n",
      "                         'layer2.1.bn2.weight': 0.039164744317531586,\n",
      "                         'layer2.1.conv1.weight': 1.0885001420974731,\n",
      "                         'layer2.1.conv2.weight': 1.0269498825073242,\n",
      "                         'layer3.0.bn1.bias': 0.038510147482156754,\n",
      "                         'layer3.0.bn1.weight': 0.04580407217144966,\n",
      "                         'layer3.0.bn2.bias': 0.034079112112522125,\n",
      "                         'layer3.0.bn2.weight': 0.05066235363483429,\n",
      "                         'layer3.0.conv1.weight': 1.3997688293457031,\n",
      "                         'layer3.0.conv2.weight': 1.2664390802383423,\n",
      "                         'layer3.0.downsample.0.weight': 0.4972435534000397,\n",
      "                         'layer3.0.downsample.1.bias': 0.034079112112522125,\n",
      "                         'layer3.0.downsample.1.weight': 0.04406815394759178,\n",
      "                         'layer3.1.bn1.bias': 0.02609845995903015,\n",
      "                         'layer3.1.bn1.weight': 0.02835334837436676,\n",
      "                         'layer3.1.bn2.bias': 0.02073424495756626,\n",
      "                         'layer3.1.bn2.weight': 0.03785020858049393,\n",
      "                         'layer3.1.conv1.weight': 1.018646001815796,\n",
      "                         'layer3.1.conv2.weight': 0.9075788855552673,\n",
      "                         'layer4.0.bn1.bias': 0.030400017276406288,\n",
      "                         'layer4.0.bn1.weight': 0.0343521349132061,\n",
      "                         'layer4.0.bn2.bias': 0.07086978852748871,\n",
      "                         'layer4.0.bn2.weight': 0.0556047149002552,\n",
      "                         'layer4.0.conv1.weight': 1.2290699481964111,\n",
      "                         'layer4.0.conv2.weight': 1.2136348485946655,\n",
      "                         'layer4.0.downsample.0.weight': 0.768915057182312,\n",
      "                         'layer4.0.downsample.1.bias': 0.07086978852748871,\n",
      "                         'layer4.0.downsample.1.weight': 0.06416917592287064,\n",
      "                         'layer4.1.bn1.bias': 0.027299288660287857,\n",
      "                         'layer4.1.bn1.weight': 0.029854832217097282,\n",
      "                         'layer4.1.bn2.bias': 0.08897915482521057,\n",
      "                         'layer4.1.bn2.weight': 0.05024086311459541,\n",
      "                         'layer4.1.conv1.weight': 1.1202911138534546,\n",
      "                         'layer4.1.conv2.weight': 1.069062352180481}},\n",
      " 3: {'batch_size': 64,\n",
      "     'class_distribution': {np.int64(0): np.int64(40),\n",
      "                            np.int64(1): np.int64(96),\n",
      "                            np.int64(3): np.int64(21),\n",
      "                            np.int64(4): np.int64(1),\n",
      "                            np.int64(5): np.int64(136),\n",
      "                            np.int64(6): np.int64(52),\n",
      "                            np.int64(7): np.int64(38),\n",
      "                            np.int64(8): np.int64(5),\n",
      "                            np.int64(9): np.int64(3),\n",
      "                            np.int64(10): np.int64(2),\n",
      "                            np.int64(11): np.int64(26),\n",
      "                            np.int64(12): np.int64(7),\n",
      "                            np.int64(13): np.int64(104),\n",
      "                            np.int64(14): np.int64(44),\n",
      "                            np.int64(15): np.int64(10),\n",
      "                            np.int64(16): np.int64(37),\n",
      "                            np.int64(17): np.int64(37),\n",
      "                            np.int64(18): np.int64(6),\n",
      "                            np.int64(19): np.int64(25),\n",
      "                            np.int64(20): np.int64(3),\n",
      "                            np.int64(21): np.int64(135),\n",
      "                            np.int64(22): np.int64(1),\n",
      "                            np.int64(23): np.int64(8),\n",
      "                            np.int64(24): np.int64(3),\n",
      "                            np.int64(25): np.int64(65),\n",
      "                            np.int64(26): np.int64(249),\n",
      "                            np.int64(27): np.int64(56),\n",
      "                            np.int64(28): np.int64(10),\n",
      "                            np.int64(29): np.int64(1),\n",
      "                            np.int64(30): np.int64(303),\n",
      "                            np.int64(31): np.int64(3),\n",
      "                            np.int64(32): np.int64(1),\n",
      "                            np.int64(33): np.int64(20),\n",
      "                            np.int64(34): np.int64(166),\n",
      "                            np.int64(35): np.int64(22),\n",
      "                            np.int64(36): np.int64(6),\n",
      "                            np.int64(37): np.int64(39),\n",
      "                            np.int64(38): np.int64(56),\n",
      "                            np.int64(39): np.int64(76),\n",
      "                            np.int64(40): np.int64(13),\n",
      "                            np.int64(41): np.int64(3),\n",
      "                            np.int64(42): np.int64(17),\n",
      "                            np.int64(43): np.int64(19),\n",
      "                            np.int64(44): np.int64(2),\n",
      "                            np.int64(45): np.int64(45),\n",
      "                            np.int64(46): np.int64(11),\n",
      "                            np.int64(47): np.int64(97),\n",
      "                            np.int64(48): np.int64(9),\n",
      "                            np.int64(49): np.int64(14),\n",
      "                            np.int64(50): np.int64(18),\n",
      "                            np.int64(51): np.int64(11),\n",
      "                            np.int64(52): np.int64(104),\n",
      "                            np.int64(53): np.int64(48),\n",
      "                            np.int64(54): np.int64(138),\n",
      "                            np.int64(55): np.int64(18),\n",
      "                            np.int64(56): np.int64(10),\n",
      "                            np.int64(57): np.int64(68),\n",
      "                            np.int64(58): np.int64(16),\n",
      "                            np.int64(59): np.int64(8),\n",
      "                            np.int64(60): np.int64(35),\n",
      "                            np.int64(61): np.int64(132),\n",
      "                            np.int64(62): np.int64(18),\n",
      "                            np.int64(63): np.int64(11),\n",
      "                            np.int64(65): np.int64(23),\n",
      "                            np.int64(66): np.int64(11),\n",
      "                            np.int64(67): np.int64(35),\n",
      "                            np.int64(68): np.int64(15),\n",
      "                            np.int64(69): np.int64(9),\n",
      "                            np.int64(70): np.int64(21),\n",
      "                            np.int64(71): np.int64(5),\n",
      "                            np.int64(72): np.int64(3),\n",
      "                            np.int64(73): np.int64(10),\n",
      "                            np.int64(74): np.int64(4),\n",
      "                            np.int64(75): np.int64(14),\n",
      "                            np.int64(76): np.int64(90),\n",
      "                            np.int64(77): np.int64(178),\n",
      "                            np.int64(79): np.int64(38),\n",
      "                            np.int64(80): np.int64(162),\n",
      "                            np.int64(81): np.int64(13),\n",
      "                            np.int64(82): np.int64(53),\n",
      "                            np.int64(83): np.int64(9),\n",
      "                            np.int64(84): np.int64(154),\n",
      "                            np.int64(85): np.int64(6),\n",
      "                            np.int64(86): np.int64(144),\n",
      "                            np.int64(87): np.int64(83),\n",
      "                            np.int64(88): np.int64(18),\n",
      "                            np.int64(89): np.int64(46),\n",
      "                            np.int64(90): np.int64(27),\n",
      "                            np.int64(91): np.int64(85),\n",
      "                            np.int64(92): np.int64(2),\n",
      "                            np.int64(93): np.int64(92),\n",
      "                            np.int64(94): np.int64(81),\n",
      "                            np.int64(95): np.int64(59),\n",
      "                            np.int64(96): np.int64(17),\n",
      "                            np.int64(97): np.int64(14)},\n",
      "     'gradient_norm': 5.401780128479004,\n",
      "     'learning_rate': 0.01,\n",
      "     'local_epochs': 1,\n",
      "     'local_loss': 2.4702420234680176,\n",
      "     'num_samples': 4299,\n",
      "     'per_layer_norms': {'bn1.bias': 0.0636722594499588,\n",
      "                         'bn1.weight': 0.10946671664714813,\n",
      "                         'conv1.weight': 1.3166335821151733,\n",
      "                         'fc.bias': 0.149139404296875,\n",
      "                         'fc.weight': 2.74300479888916,\n",
      "                         'layer1.0.bn1.bias': 0.060142241418361664,\n",
      "                         'layer1.0.bn1.weight': 0.07044777274131775,\n",
      "                         'layer1.0.bn2.bias': 0.041319429874420166,\n",
      "                         'layer1.0.bn2.weight': 0.06563793122768402,\n",
      "                         'layer1.0.conv1.weight': 1.0079830884933472,\n",
      "                         'layer1.0.conv2.weight': 0.8936602473258972,\n",
      "                         'layer1.1.bn1.bias': 0.036929745227098465,\n",
      "                         'layer1.1.bn1.weight': 0.051854006946086884,\n",
      "                         'layer1.1.bn2.bias': 0.031190089881420135,\n",
      "                         'layer1.1.bn2.weight': 0.05478784441947937,\n",
      "                         'layer1.1.conv1.weight': 0.8150778412818909,\n",
      "                         'layer1.1.conv2.weight': 0.7743982076644897,\n",
      "                         'layer2.0.bn1.bias': 0.04573715478181839,\n",
      "                         'layer2.0.bn1.weight': 0.053435295820236206,\n",
      "                         'layer2.0.bn2.bias': 0.041182857006788254,\n",
      "                         'layer2.0.bn2.weight': 0.06611873209476471,\n",
      "                         'layer2.0.conv1.weight': 1.0592230558395386,\n",
      "                         'layer2.0.conv2.weight': 1.1292632818222046,\n",
      "                         'layer2.0.downsample.0.weight': 0.4389090836048126,\n",
      "                         'layer2.0.downsample.1.bias': 0.041182857006788254,\n",
      "                         'layer2.0.downsample.1.weight': 0.0457555428147316,\n",
      "                         'layer2.1.bn1.bias': 0.03888106718659401,\n",
      "                         'layer2.1.bn1.weight': 0.04691886901855469,\n",
      "                         'layer2.1.bn2.bias': 0.027457840740680695,\n",
      "                         'layer2.1.bn2.weight': 0.04150686413049698,\n",
      "                         'layer2.1.conv1.weight': 1.0962469577789307,\n",
      "                         'layer2.1.conv2.weight': 1.0017354488372803,\n",
      "                         'layer3.0.bn1.bias': 0.03958837687969208,\n",
      "                         'layer3.0.bn1.weight': 0.04670513793826103,\n",
      "                         'layer3.0.bn2.bias': 0.034529637545347214,\n",
      "                         'layer3.0.bn2.weight': 0.049574825912714005,\n",
      "                         'layer3.0.conv1.weight': 1.3788284063339233,\n",
      "                         'layer3.0.conv2.weight': 1.2826608419418335,\n",
      "                         'layer3.0.downsample.0.weight': 0.4977494180202484,\n",
      "                         'layer3.0.downsample.1.bias': 0.034529637545347214,\n",
      "                         'layer3.0.downsample.1.weight': 0.045410364866256714,\n",
      "                         'layer3.1.bn1.bias': 0.02746398001909256,\n",
      "                         'layer3.1.bn1.weight': 0.031799979507923126,\n",
      "                         'layer3.1.bn2.bias': 0.024221699684858322,\n",
      "                         'layer3.1.bn2.weight': 0.03361589461565018,\n",
      "                         'layer3.1.conv1.weight': 1.064638614654541,\n",
      "                         'layer3.1.conv2.weight': 0.932623028755188,\n",
      "                         'layer4.0.bn1.bias': 0.02969847433269024,\n",
      "                         'layer4.0.bn1.weight': 0.03536989167332649,\n",
      "                         'layer4.0.bn2.bias': 0.062420908361673355,\n",
      "                         'layer4.0.bn2.weight': 0.057903189212083817,\n",
      "                         'layer4.0.conv1.weight': 1.2571237087249756,\n",
      "                         'layer4.0.conv2.weight': 1.2641209363937378,\n",
      "                         'layer4.0.downsample.0.weight': 0.7347750067710876,\n",
      "                         'layer4.0.downsample.1.bias': 0.062420908361673355,\n",
      "                         'layer4.0.downsample.1.weight': 0.05865328386425972,\n",
      "                         'layer4.1.bn1.bias': 0.02636587806046009,\n",
      "                         'layer4.1.bn1.weight': 0.031111786141991615,\n",
      "                         'layer4.1.bn2.bias': 0.07510747760534286,\n",
      "                         'layer4.1.bn2.weight': 0.05109597370028496,\n",
      "                         'layer4.1.conv1.weight': 1.0847269296646118,\n",
      "                         'layer4.1.conv2.weight': 1.1103746891021729}},\n",
      " 4: {'batch_size': 64,\n",
      "     'class_distribution': {np.int64(0): np.int64(208),\n",
      "                            np.int64(1): np.int64(16),\n",
      "                            np.int64(2): np.int64(263),\n",
      "                            np.int64(3): np.int64(4),\n",
      "                            np.int64(4): np.int64(3),\n",
      "                            np.int64(7): np.int64(117),\n",
      "                            np.int64(8): np.int64(24),\n",
      "                            np.int64(9): np.int64(16),\n",
      "                            np.int64(10): np.int64(117),\n",
      "                            np.int64(11): np.int64(61),\n",
      "                            np.int64(12): np.int64(4),\n",
      "                            np.int64(13): np.int64(1),\n",
      "                            np.int64(14): np.int64(42),\n",
      "                            np.int64(15): np.int64(41),\n",
      "                            np.int64(16): np.int64(116),\n",
      "                            np.int64(17): np.int64(105),\n",
      "                            np.int64(18): np.int64(17),\n",
      "                            np.int64(19): np.int64(25),\n",
      "                            np.int64(20): np.int64(99),\n",
      "                            np.int64(21): np.int64(1),\n",
      "                            np.int64(22): np.int64(151),\n",
      "                            np.int64(23): np.int64(24),\n",
      "                            np.int64(25): np.int64(24),\n",
      "                            np.int64(26): np.int64(10),\n",
      "                            np.int64(27): np.int64(49),\n",
      "                            np.int64(28): np.int64(45),\n",
      "                            np.int64(29): np.int64(77),\n",
      "                            np.int64(30): np.int64(38),\n",
      "                            np.int64(31): np.int64(1),\n",
      "                            np.int64(32): np.int64(32),\n",
      "                            np.int64(33): np.int64(119),\n",
      "                            np.int64(34): np.int64(28),\n",
      "                            np.int64(35): np.int64(104),\n",
      "                            np.int64(36): np.int64(78),\n",
      "                            np.int64(37): np.int64(159),\n",
      "                            np.int64(38): np.int64(24),\n",
      "                            np.int64(39): np.int64(17),\n",
      "                            np.int64(40): np.int64(2),\n",
      "                            np.int64(42): np.int64(157),\n",
      "                            np.int64(43): np.int64(34),\n",
      "                            np.int64(44): np.int64(27),\n",
      "                            np.int64(45): np.int64(91),\n",
      "                            np.int64(46): np.int64(44),\n",
      "                            np.int64(47): np.int64(97),\n",
      "                            np.int64(48): np.int64(1),\n",
      "                            np.int64(49): np.int64(84),\n",
      "                            np.int64(50): np.int64(4),\n",
      "                            np.int64(51): np.int64(33),\n",
      "                            np.int64(52): np.int64(80),\n",
      "                            np.int64(53): np.int64(4),\n",
      "                            np.int64(54): np.int64(94),\n",
      "                            np.int64(55): np.int64(35),\n",
      "                            np.int64(56): np.int64(26),\n",
      "                            np.int64(57): np.int64(103),\n",
      "                            np.int64(58): np.int64(1),\n",
      "                            np.int64(59): np.int64(51),\n",
      "                            np.int64(60): np.int64(21),\n",
      "                            np.int64(62): np.int64(148),\n",
      "                            np.int64(63): np.int64(7),\n",
      "                            np.int64(64): np.int64(4),\n",
      "                            np.int64(65): np.int64(61),\n",
      "                            np.int64(66): np.int64(44),\n",
      "                            np.int64(67): np.int64(21),\n",
      "                            np.int64(68): np.int64(24),\n",
      "                            np.int64(69): np.int64(46),\n",
      "                            np.int64(70): np.int64(4),\n",
      "                            np.int64(71): np.int64(20),\n",
      "                            np.int64(72): np.int64(18),\n",
      "                            np.int64(73): np.int64(19),\n",
      "                            np.int64(74): np.int64(34),\n",
      "                            np.int64(75): np.int64(10),\n",
      "                            np.int64(76): np.int64(15),\n",
      "                            np.int64(77): np.int64(3),\n",
      "                            np.int64(78): np.int64(4),\n",
      "                            np.int64(79): np.int64(7),\n",
      "                            np.int64(80): np.int64(2),\n",
      "                            np.int64(81): np.int64(237),\n",
      "                            np.int64(82): np.int64(8),\n",
      "                            np.int64(83): np.int64(54),\n",
      "                            np.int64(84): np.int64(20),\n",
      "                            np.int64(85): np.int64(12),\n",
      "                            np.int64(86): np.int64(1),\n",
      "                            np.int64(87): np.int64(31),\n",
      "                            np.int64(88): np.int64(58),\n",
      "                            np.int64(89): np.int64(102),\n",
      "                            np.int64(90): np.int64(3),\n",
      "                            np.int64(91): np.int64(60),\n",
      "                            np.int64(92): np.int64(206),\n",
      "                            np.int64(93): np.int64(21),\n",
      "                            np.int64(94): np.int64(9),\n",
      "                            np.int64(96): np.int64(5),\n",
      "                            np.int64(97): np.int64(4),\n",
      "                            np.int64(98): np.int64(1),\n",
      "                            np.int64(99): np.int64(68)},\n",
      "     'gradient_norm': 5.296031951904297,\n",
      "     'learning_rate': 0.01,\n",
      "     'local_epochs': 1,\n",
      "     'local_loss': 2.585989475250244,\n",
      "     'num_samples': 4640,\n",
      "     'per_layer_norms': {'bn1.bias': 0.061828501522541046,\n",
      "                         'bn1.weight': 0.11968004703521729,\n",
      "                         'conv1.weight': 1.2379850149154663,\n",
      "                         'fc.bias': 0.17540304362773895,\n",
      "                         'fc.weight': 3.000919818878174,\n",
      "                         'layer1.0.bn1.bias': 0.06614436209201813,\n",
      "                         'layer1.0.bn1.weight': 0.0689067542552948,\n",
      "                         'layer1.0.bn2.bias': 0.041604213416576385,\n",
      "                         'layer1.0.bn2.weight': 0.05074496939778328,\n",
      "                         'layer1.0.conv1.weight': 0.918274998664856,\n",
      "                         'layer1.0.conv2.weight': 0.8601172566413879,\n",
      "                         'layer1.1.bn1.bias': 0.03580765053629875,\n",
      "                         'layer1.1.bn1.weight': 0.041330479085445404,\n",
      "                         'layer1.1.bn2.bias': 0.02740308828651905,\n",
      "                         'layer1.1.bn2.weight': 0.04786382615566254,\n",
      "                         'layer1.1.conv1.weight': 0.7363356351852417,\n",
      "                         'layer1.1.conv2.weight': 0.7111752033233643,\n",
      "                         'layer2.0.bn1.bias': 0.04393952339887619,\n",
      "                         'layer2.0.bn1.weight': 0.051737211644649506,\n",
      "                         'layer2.0.bn2.bias': 0.04146931692957878,\n",
      "                         'layer2.0.bn2.weight': 0.05214549973607063,\n",
      "                         'layer2.0.conv1.weight': 0.9890565872192383,\n",
      "                         'layer2.0.conv2.weight': 1.080479383468628,\n",
      "                         'layer2.0.downsample.0.weight': 0.419318825006485,\n",
      "                         'layer2.0.downsample.1.bias': 0.04146931692957878,\n",
      "                         'layer2.0.downsample.1.weight': 0.046851612627506256,\n",
      "                         'layer2.1.bn1.bias': 0.038279008120298386,\n",
      "                         'layer2.1.bn1.weight': 0.042920928448438644,\n",
      "                         'layer2.1.bn2.bias': 0.031218115240335464,\n",
      "                         'layer2.1.bn2.weight': 0.043314095586538315,\n",
      "                         'layer2.1.conv1.weight': 1.034005045890808,\n",
      "                         'layer2.1.conv2.weight': 0.9244526028633118,\n",
      "                         'layer3.0.bn1.bias': 0.032579969614744186,\n",
      "                         'layer3.0.bn1.weight': 0.043815940618515015,\n",
      "                         'layer3.0.bn2.bias': 0.03311659023165703,\n",
      "                         'layer3.0.bn2.weight': 0.04987678304314613,\n",
      "                         'layer3.0.conv1.weight': 1.2879294157028198,\n",
      "                         'layer3.0.conv2.weight': 1.1865779161453247,\n",
      "                         'layer3.0.downsample.0.weight': 0.4589923322200775,\n",
      "                         'layer3.0.downsample.1.bias': 0.03311659023165703,\n",
      "                         'layer3.0.downsample.1.weight': 0.04266038164496422,\n",
      "                         'layer3.1.bn1.bias': 0.027841150760650635,\n",
      "                         'layer3.1.bn1.weight': 0.029505634680390358,\n",
      "                         'layer3.1.bn2.bias': 0.021748045459389687,\n",
      "                         'layer3.1.bn2.weight': 0.03433692455291748,\n",
      "                         'layer3.1.conv1.weight': 0.9636285305023193,\n",
      "                         'layer3.1.conv2.weight': 0.8803932070732117,\n",
      "                         'layer4.0.bn1.bias': 0.030225390568375587,\n",
      "                         'layer4.0.bn1.weight': 0.03494087979197502,\n",
      "                         'layer4.0.bn2.bias': 0.07127179950475693,\n",
      "                         'layer4.0.bn2.weight': 0.05529089272022247,\n",
      "                         'layer4.0.conv1.weight': 1.1740078926086426,\n",
      "                         'layer4.0.conv2.weight': 1.194235920906067,\n",
      "                         'layer4.0.downsample.0.weight': 0.7361173629760742,\n",
      "                         'layer4.0.downsample.1.bias': 0.07127179950475693,\n",
      "                         'layer4.0.downsample.1.weight': 0.06548581272363663,\n",
      "                         'layer4.1.bn1.bias': 0.026157818734645844,\n",
      "                         'layer4.1.bn1.weight': 0.027960114181041718,\n",
      "                         'layer4.1.bn2.bias': 0.08797434717416763,\n",
      "                         'layer4.1.bn2.weight': 0.05047882720828056,\n",
      "                         'layer4.1.conv1.weight': 1.0104738473892212,\n",
      "                         'layer4.1.conv2.weight': 1.0739647150039673}},\n",
      " 5: {'batch_size': 64,\n",
      "     'class_distribution': {np.int64(0): np.int64(21),\n",
      "                            np.int64(1): np.int64(74),\n",
      "                            np.int64(2): np.int64(20),\n",
      "                            np.int64(3): np.int64(20),\n",
      "                            np.int64(4): np.int64(15),\n",
      "                            np.int64(5): np.int64(26),\n",
      "                            np.int64(6): np.int64(54),\n",
      "                            np.int64(7): np.int64(23),\n",
      "                            np.int64(8): np.int64(14),\n",
      "                            np.int64(9): np.int64(14),\n",
      "                            np.int64(10): np.int64(109),\n",
      "                            np.int64(11): np.int64(10),\n",
      "                            np.int64(12): np.int64(12),\n",
      "                            np.int64(13): np.int64(14),\n",
      "                            np.int64(14): np.int64(118),\n",
      "                            np.int64(15): np.int64(222),\n",
      "                            np.int64(16): np.int64(3),\n",
      "                            np.int64(17): np.int64(10),\n",
      "                            np.int64(18): np.int64(276),\n",
      "                            np.int64(19): np.int64(1),\n",
      "                            np.int64(20): np.int64(19),\n",
      "                            np.int64(21): np.int64(83),\n",
      "                            np.int64(22): np.int64(59),\n",
      "                            np.int64(23): np.int64(3),\n",
      "                            np.int64(25): np.int64(97),\n",
      "                            np.int64(26): np.int64(69),\n",
      "                            np.int64(27): np.int64(139),\n",
      "                            np.int64(28): np.int64(66),\n",
      "                            np.int64(29): np.int64(183),\n",
      "                            np.int64(30): np.int64(43),\n",
      "                            np.int64(32): np.int64(244),\n",
      "                            np.int64(33): np.int64(17),\n",
      "                            np.int64(34): np.int64(109),\n",
      "                            np.int64(35): np.int64(4),\n",
      "                            np.int64(36): np.int64(80),\n",
      "                            np.int64(37): np.int64(12),\n",
      "                            np.int64(38): np.int64(29),\n",
      "                            np.int64(39): np.int64(38),\n",
      "                            np.int64(40): np.int64(262),\n",
      "                            np.int64(41): np.int64(74),\n",
      "                            np.int64(42): np.int64(79),\n",
      "                            np.int64(43): np.int64(7),\n",
      "                            np.int64(44): np.int64(47),\n",
      "                            np.int64(45): np.int64(2),\n",
      "                            np.int64(46): np.int64(5),\n",
      "                            np.int64(47): np.int64(29),\n",
      "                            np.int64(48): np.int64(13),\n",
      "                            np.int64(49): np.int64(46),\n",
      "                            np.int64(50): np.int64(213),\n",
      "                            np.int64(51): np.int64(93),\n",
      "                            np.int64(52): np.int64(23),\n",
      "                            np.int64(53): np.int64(140),\n",
      "                            np.int64(54): np.int64(50),\n",
      "                            np.int64(55): np.int64(55),\n",
      "                            np.int64(56): np.int64(3),\n",
      "                            np.int64(57): np.int64(177),\n",
      "                            np.int64(58): np.int64(3),\n",
      "                            np.int64(60): np.int64(39),\n",
      "                            np.int64(61): np.int64(11),\n",
      "                            np.int64(62): np.int64(9),\n",
      "                            np.int64(63): np.int64(94),\n",
      "                            np.int64(64): np.int64(18),\n",
      "                            np.int64(65): np.int64(28),\n",
      "                            np.int64(66): np.int64(151),\n",
      "                            np.int64(67): np.int64(68),\n",
      "                            np.int64(68): np.int64(2),\n",
      "                            np.int64(69): np.int64(9),\n",
      "                            np.int64(70): np.int64(8),\n",
      "                            np.int64(71): np.int64(74),\n",
      "                            np.int64(72): np.int64(199),\n",
      "                            np.int64(73): np.int64(9),\n",
      "                            np.int64(74): np.int64(6),\n",
      "                            np.int64(75): np.int64(37),\n",
      "                            np.int64(76): np.int64(9),\n",
      "                            np.int64(77): np.int64(168),\n",
      "                            np.int64(78): np.int64(136),\n",
      "                            np.int64(79): np.int64(11),\n",
      "                            np.int64(80): np.int64(48),\n",
      "                            np.int64(81): np.int64(29),\n",
      "                            np.int64(82): np.int64(2),\n",
      "                            np.int64(83): np.int64(7),\n",
      "                            np.int64(84): np.int64(59),\n",
      "                            np.int64(85): np.int64(27),\n",
      "                            np.int64(86): np.int64(34),\n",
      "                            np.int64(87): np.int64(6),\n",
      "                            np.int64(88): np.int64(2),\n",
      "                            np.int64(89): np.int64(4),\n",
      "                            np.int64(90): np.int64(19),\n",
      "                            np.int64(91): np.int64(3),\n",
      "                            np.int64(92): np.int64(5),\n",
      "                            np.int64(93): np.int64(9),\n",
      "                            np.int64(94): np.int64(147),\n",
      "                            np.int64(95): np.int64(308),\n",
      "                            np.int64(96): np.int64(15),\n",
      "                            np.int64(97): np.int64(80),\n",
      "                            np.int64(98): np.int64(61)},\n",
      "     'gradient_norm': 4.976016521453857,\n",
      "     'learning_rate': 0.01,\n",
      "     'local_epochs': 1,\n",
      "     'local_loss': 2.5223548412323,\n",
      "     'num_samples': 5622,\n",
      "     'per_layer_norms': {'bn1.bias': 0.057792630046606064,\n",
      "                         'bn1.weight': 0.13401862978935242,\n",
      "                         'conv1.weight': 1.180086612701416,\n",
      "                         'fc.bias': 0.13346374034881592,\n",
      "                         'fc.weight': 2.3056585788726807,\n",
      "                         'layer1.0.bn1.bias': 0.06737025082111359,\n",
      "                         'layer1.0.bn1.weight': 0.05890047922730446,\n",
      "                         'layer1.0.bn2.bias': 0.044308140873909,\n",
      "                         'layer1.0.bn2.weight': 0.07059357315301895,\n",
      "                         'layer1.0.conv1.weight': 0.9472883343696594,\n",
      "                         'layer1.0.conv2.weight': 0.9046499729156494,\n",
      "                         'layer1.1.bn1.bias': 0.04012810066342354,\n",
      "                         'layer1.1.bn1.weight': 0.0494384728372097,\n",
      "                         'layer1.1.bn2.bias': 0.030697785317897797,\n",
      "                         'layer1.1.bn2.weight': 0.045519351959228516,\n",
      "                         'layer1.1.conv1.weight': 0.8009128570556641,\n",
      "                         'layer1.1.conv2.weight': 0.7680134177207947,\n",
      "                         'layer2.0.bn1.bias': 0.05170184746384621,\n",
      "                         'layer2.0.bn1.weight': 0.05280259996652603,\n",
      "                         'layer2.0.bn2.bias': 0.04419498145580292,\n",
      "                         'layer2.0.bn2.weight': 0.057780660688877106,\n",
      "                         'layer2.0.conv1.weight': 1.0249110460281372,\n",
      "                         'layer2.0.conv2.weight': 1.104825735092163,\n",
      "                         'layer2.0.downsample.0.weight': 0.4372193515300751,\n",
      "                         'layer2.0.downsample.1.bias': 0.04419498145580292,\n",
      "                         'layer2.0.downsample.1.weight': 0.054448045790195465,\n",
      "                         'layer2.1.bn1.bias': 0.036622751504182816,\n",
      "                         'layer2.1.bn1.weight': 0.04433391988277435,\n",
      "                         'layer2.1.bn2.bias': 0.029201164841651917,\n",
      "                         'layer2.1.bn2.weight': 0.040384504944086075,\n",
      "                         'layer2.1.conv1.weight': 1.0453022718429565,\n",
      "                         'layer2.1.conv2.weight': 0.9759728908538818,\n",
      "                         'layer3.0.bn1.bias': 0.03748089820146561,\n",
      "                         'layer3.0.bn1.weight': 0.04396503046154976,\n",
      "                         'layer3.0.bn2.bias': 0.0349714420735836,\n",
      "                         'layer3.0.bn2.weight': 0.04606887325644493,\n",
      "                         'layer3.0.conv1.weight': 1.3231430053710938,\n",
      "                         'layer3.0.conv2.weight': 1.2305691242218018,\n",
      "                         'layer3.0.downsample.0.weight': 0.46798408031463623,\n",
      "                         'layer3.0.downsample.1.bias': 0.0349714420735836,\n",
      "                         'layer3.0.downsample.1.weight': 0.03776200860738754,\n",
      "                         'layer3.1.bn1.bias': 0.026672709733247757,\n",
      "                         'layer3.1.bn1.weight': 0.02830941416323185,\n",
      "                         'layer3.1.bn2.bias': 0.022519845515489578,\n",
      "                         'layer3.1.bn2.weight': 0.03365053981542587,\n",
      "                         'layer3.1.conv1.weight': 0.9814335703849792,\n",
      "                         'layer3.1.conv2.weight': 0.8802897334098816,\n",
      "                         'layer4.0.bn1.bias': 0.028188347816467285,\n",
      "                         'layer4.0.bn1.weight': 0.03214547038078308,\n",
      "                         'layer4.0.bn2.bias': 0.06210679933428764,\n",
      "                         'layer4.0.bn2.weight': 0.054355937987565994,\n",
      "                         'layer4.0.conv1.weight': 1.1695019006729126,\n",
      "                         'layer4.0.conv2.weight': 1.171258807182312,\n",
      "                         'layer4.0.downsample.0.weight': 0.717767059803009,\n",
      "                         'layer4.0.downsample.1.bias': 0.06210679933428764,\n",
      "                         'layer4.0.downsample.1.weight': 0.05840378254652023,\n",
      "                         'layer4.1.bn1.bias': 0.025144316256046295,\n",
      "                         'layer4.1.bn1.weight': 0.028633203357458115,\n",
      "                         'layer4.1.bn2.bias': 0.07122736424207687,\n",
      "                         'layer4.1.bn2.weight': 0.04554235190153122,\n",
      "                         'layer4.1.conv1.weight': 1.012626051902771,\n",
      "                         'layer4.1.conv2.weight': 0.9877699017524719}},\n",
      " 7: {'batch_size': 64,\n",
      "     'class_distribution': {np.int64(0): np.int64(2),\n",
      "                            np.int64(1): np.int64(44),\n",
      "                            np.int64(2): np.int64(104),\n",
      "                            np.int64(3): np.int64(3),\n",
      "                            np.int64(4): np.int64(2),\n",
      "                            np.int64(5): np.int64(48),\n",
      "                            np.int64(6): np.int64(17),\n",
      "                            np.int64(7): np.int64(2),\n",
      "                            np.int64(8): np.int64(79),\n",
      "                            np.int64(9): np.int64(9),\n",
      "                            np.int64(10): np.int64(103),\n",
      "                            np.int64(11): np.int64(30),\n",
      "                            np.int64(12): np.int64(106),\n",
      "                            np.int64(13): np.int64(9),\n",
      "                            np.int64(14): np.int64(8),\n",
      "                            np.int64(15): np.int64(39),\n",
      "                            np.int64(16): np.int64(5),\n",
      "                            np.int64(17): np.int64(46),\n",
      "                            np.int64(18): np.int64(89),\n",
      "                            np.int64(20): np.int64(1),\n",
      "                            np.int64(21): np.int64(72),\n",
      "                            np.int64(22): np.int64(22),\n",
      "                            np.int64(23): np.int64(59),\n",
      "                            np.int64(24): np.int64(17),\n",
      "                            np.int64(25): np.int64(38),\n",
      "                            np.int64(26): np.int64(111),\n",
      "                            np.int64(27): np.int64(1),\n",
      "                            np.int64(28): np.int64(9),\n",
      "                            np.int64(29): np.int64(5),\n",
      "                            np.int64(30): np.int64(6),\n",
      "                            np.int64(31): np.int64(133),\n",
      "                            np.int64(32): np.int64(14),\n",
      "                            np.int64(34): np.int64(26),\n",
      "                            np.int64(35): np.int64(34),\n",
      "                            np.int64(36): np.int64(10),\n",
      "                            np.int64(37): np.int64(145),\n",
      "                            np.int64(38): np.int64(31),\n",
      "                            np.int64(39): np.int64(1),\n",
      "                            np.int64(40): np.int64(46),\n",
      "                            np.int64(41): np.int64(63),\n",
      "                            np.int64(42): np.int64(44),\n",
      "                            np.int64(43): np.int64(110),\n",
      "                            np.int64(44): np.int64(109),\n",
      "                            np.int64(45): np.int64(47),\n",
      "                            np.int64(46): np.int64(102),\n",
      "                            np.int64(47): np.int64(33),\n",
      "                            np.int64(48): np.int64(28),\n",
      "                            np.int64(49): np.int64(52),\n",
      "                            np.int64(50): np.int64(159),\n",
      "                            np.int64(51): np.int64(1),\n",
      "                            np.int64(52): np.int64(56),\n",
      "                            np.int64(53): np.int64(55),\n",
      "                            np.int64(54): np.int64(163),\n",
      "                            np.int64(55): np.int64(1),\n",
      "                            np.int64(56): np.int64(90),\n",
      "                            np.int64(57): np.int64(41),\n",
      "                            np.int64(59): np.int64(4),\n",
      "                            np.int64(62): np.int64(4),\n",
      "                            np.int64(63): np.int64(78),\n",
      "                            np.int64(64): np.int64(134),\n",
      "                            np.int64(65): np.int64(79),\n",
      "                            np.int64(67): np.int64(7),\n",
      "                            np.int64(68): np.int64(282),\n",
      "                            np.int64(69): np.int64(3),\n",
      "                            np.int64(70): np.int64(146),\n",
      "                            np.int64(72): np.int64(119),\n",
      "                            np.int64(73): np.int64(40),\n",
      "                            np.int64(74): np.int64(78),\n",
      "                            np.int64(75): np.int64(87),\n",
      "                            np.int64(76): np.int64(12),\n",
      "                            np.int64(77): np.int64(76),\n",
      "                            np.int64(78): np.int64(10),\n",
      "                            np.int64(80): np.int64(40),\n",
      "                            np.int64(81): np.int64(7),\n",
      "                            np.int64(82): np.int64(216),\n",
      "                            np.int64(83): np.int64(13),\n",
      "                            np.int64(84): np.int64(4),\n",
      "                            np.int64(85): np.int64(11),\n",
      "                            np.int64(86): np.int64(2),\n",
      "                            np.int64(87): np.int64(2),\n",
      "                            np.int64(88): np.int64(14),\n",
      "                            np.int64(89): np.int64(81),\n",
      "                            np.int64(90): np.int64(44),\n",
      "                            np.int64(91): np.int64(61),\n",
      "                            np.int64(92): np.int64(111),\n",
      "                            np.int64(93): np.int64(20),\n",
      "                            np.int64(94): np.int64(59),\n",
      "                            np.int64(96): np.int64(8),\n",
      "                            np.int64(97): np.int64(36),\n",
      "                            np.int64(98): np.int64(131),\n",
      "                            np.int64(99): np.int64(54)},\n",
      "     'gradient_norm': 5.578452110290527,\n",
      "     'learning_rate': 0.01,\n",
      "     'local_epochs': 1,\n",
      "     'local_loss': 2.6995081901550293,\n",
      "     'num_samples': 4753,\n",
      "     'per_layer_norms': {'bn1.bias': 0.07413087040185928,\n",
      "                         'bn1.weight': 0.125900536775589,\n",
      "                         'conv1.weight': 1.4191551208496094,\n",
      "                         'fc.bias': 0.1377401053905487,\n",
      "                         'fc.weight': 2.688174247741699,\n",
      "                         'layer1.0.bn1.bias': 0.07167256623506546,\n",
      "                         'layer1.0.bn1.weight': 0.07549413293600082,\n",
      "                         'layer1.0.bn2.bias': 0.04968203231692314,\n",
      "                         'layer1.0.bn2.weight': 0.07233336567878723,\n",
      "                         'layer1.0.conv1.weight': 1.042332649230957,\n",
      "                         'layer1.0.conv2.weight': 0.9439223408699036,\n",
      "                         'layer1.1.bn1.bias': 0.04176444187760353,\n",
      "                         'layer1.1.bn1.weight': 0.04617708548903465,\n",
      "                         'layer1.1.bn2.bias': 0.028808070346713066,\n",
      "                         'layer1.1.bn2.weight': 0.04984652251005173,\n",
      "                         'layer1.1.conv1.weight': 0.8330699801445007,\n",
      "                         'layer1.1.conv2.weight': 0.7895757555961609,\n",
      "                         'layer2.0.bn1.bias': 0.0449080765247345,\n",
      "                         'layer2.0.bn1.weight': 0.049149803817272186,\n",
      "                         'layer2.0.bn2.bias': 0.05452996864914894,\n",
      "                         'layer2.0.bn2.weight': 0.06102343648672104,\n",
      "                         'layer2.0.conv1.weight': 1.145025610923767,\n",
      "                         'layer2.0.conv2.weight': 1.229005217552185,\n",
      "                         'layer2.0.downsample.0.weight': 0.4665134847164154,\n",
      "                         'layer2.0.downsample.1.bias': 0.05452996864914894,\n",
      "                         'layer2.0.downsample.1.weight': 0.06304808706045151,\n",
      "                         'layer2.1.bn1.bias': 0.04292669892311096,\n",
      "                         'layer2.1.bn1.weight': 0.04736969992518425,\n",
      "                         'layer2.1.bn2.bias': 0.03346548601984978,\n",
      "                         'layer2.1.bn2.weight': 0.04619418457150459,\n",
      "                         'layer2.1.conv1.weight': 1.1904466152191162,\n",
      "                         'layer2.1.conv2.weight': 1.0818217992782593,\n",
      "                         'layer3.0.bn1.bias': 0.039739057421684265,\n",
      "                         'layer3.0.bn1.weight': 0.050094328820705414,\n",
      "                         'layer3.0.bn2.bias': 0.03826124593615532,\n",
      "                         'layer3.0.bn2.weight': 0.05053720995783806,\n",
      "                         'layer3.0.conv1.weight': 1.4743313789367676,\n",
      "                         'layer3.0.conv2.weight': 1.3443810939788818,\n",
      "                         'layer3.0.downsample.0.weight': 0.5134070515632629,\n",
      "                         'layer3.0.downsample.1.bias': 0.03826124593615532,\n",
      "                         'layer3.0.downsample.1.weight': 0.04547744244337082,\n",
      "                         'layer3.1.bn1.bias': 0.027561256662011147,\n",
      "                         'layer3.1.bn1.weight': 0.03000720590353012,\n",
      "                         'layer3.1.bn2.bias': 0.02356097660958767,\n",
      "                         'layer3.1.bn2.weight': 0.033849336206912994,\n",
      "                         'layer3.1.conv1.weight': 1.0846459865570068,\n",
      "                         'layer3.1.conv2.weight': 0.9606371521949768,\n",
      "                         'layer4.0.bn1.bias': 0.029525892809033394,\n",
      "                         'layer4.0.bn1.weight': 0.03284318372607231,\n",
      "                         'layer4.0.bn2.bias': 0.061321694403886795,\n",
      "                         'layer4.0.bn2.weight': 0.05749138817191124,\n",
      "                         'layer4.0.conv1.weight': 1.332871913909912,\n",
      "                         'layer4.0.conv2.weight': 1.2844276428222656,\n",
      "                         'layer4.0.downsample.0.weight': 0.7462396621704102,\n",
      "                         'layer4.0.downsample.1.bias': 0.061321694403886795,\n",
      "                         'layer4.0.downsample.1.weight': 0.06223638355731964,\n",
      "                         'layer4.1.bn1.bias': 0.02579197846353054,\n",
      "                         'layer4.1.bn1.weight': 0.028652077540755272,\n",
      "                         'layer4.1.bn2.bias': 0.07449395954608917,\n",
      "                         'layer4.1.bn2.weight': 0.04991146922111511,\n",
      "                         'layer4.1.conv1.weight': 1.1124616861343384,\n",
      "                         'layer4.1.conv2.weight': 1.122506856918335}},\n",
      " 9: {'batch_size': 64,\n",
      "     'class_distribution': {np.int64(0): np.int64(36),\n",
      "                            np.int64(1): np.int64(14),\n",
      "                            np.int64(2): np.int64(3),\n",
      "                            np.int64(3): np.int64(39),\n",
      "                            np.int64(4): np.int64(1),\n",
      "                            np.int64(5): np.int64(2),\n",
      "                            np.int64(6): np.int64(36),\n",
      "                            np.int64(7): np.int64(1),\n",
      "                            np.int64(8): np.int64(250),\n",
      "                            np.int64(9): np.int64(120),\n",
      "                            np.int64(10): np.int64(14),\n",
      "                            np.int64(11): np.int64(78),\n",
      "                            np.int64(12): np.int64(7),\n",
      "                            np.int64(13): np.int64(164),\n",
      "                            np.int64(14): np.int64(14),\n",
      "                            np.int64(15): np.int64(30),\n",
      "                            np.int64(16): np.int64(104),\n",
      "                            np.int64(17): np.int64(3),\n",
      "                            np.int64(18): np.int64(29),\n",
      "                            np.int64(19): np.int64(81),\n",
      "                            np.int64(20): np.int64(4),\n",
      "                            np.int64(21): np.int64(1),\n",
      "                            np.int64(22): np.int64(112),\n",
      "                            np.int64(23): np.int64(9),\n",
      "                            np.int64(24): np.int64(14),\n",
      "                            np.int64(25): np.int64(37),\n",
      "                            np.int64(26): np.int64(16),\n",
      "                            np.int64(27): np.int64(105),\n",
      "                            np.int64(28): np.int64(24),\n",
      "                            np.int64(29): np.int64(1),\n",
      "                            np.int64(30): np.int64(35),\n",
      "                            np.int64(31): np.int64(3),\n",
      "                            np.int64(32): np.int64(11),\n",
      "                            np.int64(33): np.int64(30),\n",
      "                            np.int64(34): np.int64(6),\n",
      "                            np.int64(35): np.int64(51),\n",
      "                            np.int64(36): np.int64(25),\n",
      "                            np.int64(37): np.int64(1),\n",
      "                            np.int64(38): np.int64(36),\n",
      "                            np.int64(39): np.int64(5),\n",
      "                            np.int64(40): np.int64(3),\n",
      "                            np.int64(41): np.int64(35),\n",
      "                            np.int64(42): np.int64(6),\n",
      "                            np.int64(43): np.int64(15),\n",
      "                            np.int64(44): np.int64(73),\n",
      "                            np.int64(45): np.int64(87),\n",
      "                            np.int64(46): np.int64(44),\n",
      "                            np.int64(47): np.int64(45),\n",
      "                            np.int64(48): np.int64(5),\n",
      "                            np.int64(49): np.int64(97),\n",
      "                            np.int64(50): np.int64(23),\n",
      "                            np.int64(51): np.int64(226),\n",
      "                            np.int64(52): np.int64(24),\n",
      "                            np.int64(53): np.int64(107),\n",
      "                            np.int64(54): np.int64(7),\n",
      "                            np.int64(55): np.int64(137),\n",
      "                            np.int64(56): np.int64(108),\n",
      "                            np.int64(57): np.int64(7),\n",
      "                            np.int64(58): np.int64(4),\n",
      "                            np.int64(59): np.int64(11),\n",
      "                            np.int64(60): np.int64(1),\n",
      "                            np.int64(61): np.int64(24),\n",
      "                            np.int64(62): np.int64(1),\n",
      "                            np.int64(63): np.int64(5),\n",
      "                            np.int64(64): np.int64(2),\n",
      "                            np.int64(65): np.int64(13),\n",
      "                            np.int64(66): np.int64(98),\n",
      "                            np.int64(67): np.int64(100),\n",
      "                            np.int64(68): np.int64(1),\n",
      "                            np.int64(69): np.int64(284),\n",
      "                            np.int64(70): np.int64(25),\n",
      "                            np.int64(71): np.int64(20),\n",
      "                            np.int64(72): np.int64(72),\n",
      "                            np.int64(73): np.int64(11),\n",
      "                            np.int64(74): np.int64(27),\n",
      "                            np.int64(75): np.int64(6),\n",
      "                            np.int64(76): np.int64(130),\n",
      "                            np.int64(77): np.int64(10),\n",
      "                            np.int64(78): np.int64(152),\n",
      "                            np.int64(79): np.int64(28),\n",
      "                            np.int64(80): np.int64(37),\n",
      "                            np.int64(81): np.int64(50),\n",
      "                            np.int64(82): np.int64(12),\n",
      "                            np.int64(83): np.int64(23),\n",
      "                            np.int64(84): np.int64(23),\n",
      "                            np.int64(85): np.int64(5),\n",
      "                            np.int64(86): np.int64(102),\n",
      "                            np.int64(87): np.int64(17),\n",
      "                            np.int64(88): np.int64(229),\n",
      "                            np.int64(89): np.int64(2),\n",
      "                            np.int64(90): np.int64(74),\n",
      "                            np.int64(91): np.int64(9),\n",
      "                            np.int64(92): np.int64(28),\n",
      "                            np.int64(93): np.int64(2),\n",
      "                            np.int64(94): np.int64(8),\n",
      "                            np.int64(95): np.int64(3),\n",
      "                            np.int64(96): np.int64(265),\n",
      "                            np.int64(97): np.int64(7),\n",
      "                            np.int64(98): np.int64(125),\n",
      "                            np.int64(99): np.int64(319)},\n",
      "     'gradient_norm': 5.468667507171631,\n",
      "     'learning_rate': 0.01,\n",
      "     'local_epochs': 1,\n",
      "     'local_loss': 2.7888381481170654,\n",
      "     'num_samples': 4966,\n",
      "     'per_layer_norms': {'bn1.bias': 0.07051468640565872,\n",
      "                         'bn1.weight': 0.1092570349574089,\n",
      "                         'conv1.weight': 1.2433061599731445,\n",
      "                         'fc.bias': 0.16509516537189484,\n",
      "                         'fc.weight': 2.8322575092315674,\n",
      "                         'layer1.0.bn1.bias': 0.05858045071363449,\n",
      "                         'layer1.0.bn1.weight': 0.06304629147052765,\n",
      "                         'layer1.0.bn2.bias': 0.04279111698269844,\n",
      "                         'layer1.0.bn2.weight': 0.06337208300828934,\n",
      "                         'layer1.0.conv1.weight': 1.0153818130493164,\n",
      "                         'layer1.0.conv2.weight': 0.9135950207710266,\n",
      "                         'layer1.1.bn1.bias': 0.04573136195540428,\n",
      "                         'layer1.1.bn1.weight': 0.04739399999380112,\n",
      "                         'layer1.1.bn2.bias': 0.02777942270040512,\n",
      "                         'layer1.1.bn2.weight': 0.05226592719554901,\n",
      "                         'layer1.1.conv1.weight': 0.8112436532974243,\n",
      "                         'layer1.1.conv2.weight': 0.7804553508758545,\n",
      "                         'layer2.0.bn1.bias': 0.042028091847896576,\n",
      "                         'layer2.0.bn1.weight': 0.05601508170366287,\n",
      "                         'layer2.0.bn2.bias': 0.04440063610672951,\n",
      "                         'layer2.0.bn2.weight': 0.06103828549385071,\n",
      "                         'layer2.0.conv1.weight': 1.1123243570327759,\n",
      "                         'layer2.0.conv2.weight': 1.1666957139968872,\n",
      "                         'layer2.0.downsample.0.weight': 0.4524994492530823,\n",
      "                         'layer2.0.downsample.1.bias': 0.04440063610672951,\n",
      "                         'layer2.0.downsample.1.weight': 0.05514555051922798,\n",
      "                         'layer2.1.bn1.bias': 0.04241795837879181,\n",
      "                         'layer2.1.bn1.weight': 0.04811101406812668,\n",
      "                         'layer2.1.bn2.bias': 0.033405303955078125,\n",
      "                         'layer2.1.bn2.weight': 0.04261104390025139,\n",
      "                         'layer2.1.conv1.weight': 1.1235865354537964,\n",
      "                         'layer2.1.conv2.weight': 1.0251270532608032,\n",
      "                         'layer3.0.bn1.bias': 0.03814530372619629,\n",
      "                         'layer3.0.bn1.weight': 0.04478803649544716,\n",
      "                         'layer3.0.bn2.bias': 0.03656031936407089,\n",
      "                         'layer3.0.bn2.weight': 0.0479879193007946,\n",
      "                         'layer3.0.conv1.weight': 1.413064956665039,\n",
      "                         'layer3.0.conv2.weight': 1.2890783548355103,\n",
      "                         'layer3.0.downsample.0.weight': 0.48392054438591003,\n",
      "                         'layer3.0.downsample.1.bias': 0.03656031936407089,\n",
      "                         'layer3.0.downsample.1.weight': 0.04228304699063301,\n",
      "                         'layer3.1.bn1.bias': 0.026591574773192406,\n",
      "                         'layer3.1.bn1.weight': 0.030361589044332504,\n",
      "                         'layer3.1.bn2.bias': 0.022804629057645798,\n",
      "                         'layer3.1.bn2.weight': 0.03470098227262497,\n",
      "                         'layer3.1.conv1.weight': 1.0442099571228027,\n",
      "                         'layer3.1.conv2.weight': 0.9327116012573242,\n",
      "                         'layer4.0.bn1.bias': 0.03024306334555149,\n",
      "                         'layer4.0.bn1.weight': 0.03269778564572334,\n",
      "                         'layer4.0.bn2.bias': 0.07196798175573349,\n",
      "                         'layer4.0.bn2.weight': 0.06371685862541199,\n",
      "                         'layer4.0.conv1.weight': 1.2319520711898804,\n",
      "                         'layer4.0.conv2.weight': 1.2418420314788818,\n",
      "                         'layer4.0.downsample.0.weight': 0.7638589143753052,\n",
      "                         'layer4.0.downsample.1.bias': 0.07196798175573349,\n",
      "                         'layer4.0.downsample.1.weight': 0.06839202344417572,\n",
      "                         'layer4.1.bn1.bias': 0.028844423592090607,\n",
      "                         'layer4.1.bn1.weight': 0.029872791841626167,\n",
      "                         'layer4.1.bn2.bias': 0.09383533149957657,\n",
      "                         'layer4.1.bn2.weight': 0.05711069330573082,\n",
      "                         'layer4.1.conv1.weight': 1.1115808486938477,\n",
      "                         'layer4.1.conv2.weight': 1.105031132698059}}}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(metrics_to_export[\"client_metrics\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c72f77",
   "metadata": {},
   "source": [
    "Saving the full object locally (so we can load it later for analysis or privacy-attack experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbb5874",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"fed_metrics_round20.pkl\", \"wb\") as f:\n",
    "    pickle.dump(metrics_to_export, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e704473",
   "metadata": {},
   "source": [
    "Then we can reload later with:\n",
    "\n",
    "\"\n",
    "\n",
    "with open(\"fed_metrics_round20.pkl\", \"rb\") as f:\n",
    "    m = pickle.load(f)\n",
    "\n",
    "\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl_privacy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
