{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e11facad-c2f7-41ae-8723-a20790f56253",
   "metadata": {},
   "source": [
    "\n",
    "## Yin Attack (See-Through-Gradients) on CIFAR-100\n",
    "\n",
    "**Objective:** Reconstruct training data from gradients captured during federated learning simulation.\n",
    "\n",
    "**Attack Configuration:**\n",
    "- Attack: Yin (See-Through-Gradients)\n",
    "- Target: FL gradients from ResNet18 on CIFAR-100\n",
    "- Batch size: (IDK which one works the best)\n",
    "- Device: GPU (CUDA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f99258-d95d-4a9b-9a76-14ce8222ed2a",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "335f7bfb-ae7e-4b18-84d4-382fca626635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import breaching\n",
    "import torchvision.models as models\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ccf515-0c92-4c50-a34d-533ead8a8398",
   "metadata": {},
   "source": [
    "## 2. Configure Breaching Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb97a96c-eb1a-4bee-a123-355c290c70d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/rbhandar/.local/lib/python3.12/site-packages/breaching/__init__.py:18: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with hydra.initialize(config_path=\"config\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigating use case single_imagenet with server type honest_but_curious.\n",
      "Attack type: {'see-through-gradients'}\n"
     ]
    }
   ],
   "source": [
    "# Configure Breaching for Yin (See-Through-Gradients) attack\n",
    "cfg = breaching.get_config(overrides=[\"attack=seethroughgradients\"])\n",
    "print(f\"Attack type:\", {cfg.attack.type})\n",
    "cfg.attack.regularization = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d810f443-1eeb-4363-b0f5-df0fe07c5acf",
   "metadata": {},
   "source": [
    "## 3. Load FL Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "755d5875-b694-4425-9ffe-f92fb34fe7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded\n"
     ]
    }
   ],
   "source": [
    "# Load saved gradients from FL simulation\n",
    "gradient_dir = Path(\"/scratch/project_2015432/Sec_FL_ritesh/src/fl_simulation\")\n",
    "gradient_files = sorted(gradient_dir.glob(\"fedavg_metrics_*_tensors.pt\"))\n",
    "grad_file = gradient_files[0]\n",
    "gradient_data = torch.load(grad_file, map_location='cpu')\n",
    "print(\"Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c0e25e-4fb4-4e91-bb0a-661becfd619b",
   "metadata": {},
   "source": [
    "## 4. Load Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e0159a5-67bd-44e9-8ae4-0bfa2a694f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/rbhandar/.local/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/users/rbhandar/.local/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model loaded\n"
     ]
    }
   ],
   "source": [
    "model_state = gradient_data['global_model_state']\n",
    "model = models.resnet18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 100)  # CIFAR-100 has 100 classes\n",
    "model.load_state_dict(model_state, strict=False)\n",
    "model.eval()\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "setup = dict(device=torch.device('cuda'), dtype=torch.float32)\n",
    "attacker = breaching.attacks.prepare_attack(model, loss_fn, cfg.attack, setup)\n",
    "print(\" Model loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4ec454-d2d6-49e0-9c6b-29c1a6ec82e4",
   "metadata": {},
   "source": [
    "## 5. Extract Client Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be8e1a95-1952-42f5-8897-fc972c1c4bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client: 9\n",
      "Number of gradient tensors: 62\n"
     ]
    }
   ],
   "source": [
    "# Get gradients from first client, first training step\n",
    "client_id = list(gradient_data['raw_gradients'].keys())[0]\n",
    "client_grads = gradient_data['raw_gradients'][client_id]\n",
    "grad_dict = client_grads['grads_per_step_raw'][0]\n",
    "gradients = [grad_dict[key] for key in sorted(grad_dict.keys())]\n",
    "print(f\"Client: {client_id}\")\n",
    "print(f\"Number of gradient tensors: {len(gradients)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93558a62-1c0f-402e-bb4b-69e1448cd951",
   "metadata": {},
   "source": [
    "## 6. Prepare Data Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7599d13-2c56-44f8-a434-4645b233ec98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 62\n",
      "Buffers: 60\n",
      " Data prepared with dummy label\n"
     ]
    }
   ],
   "source": [
    "# Define CIFAR-100 metadata and separate model parameters/buffers\n",
    "class DataConfig:\n",
    "    modality = \"vision\"\n",
    "    size = (50_000,)\n",
    "    classes = 100\n",
    "    shape = (3, 32, 32)\n",
    "    normalize = True\n",
    "    mean = (0.5071, 0.4867, 0.4408)\n",
    "    std = (0.2675, 0.2565, 0.2761)\n",
    "\n",
    "data_cfg = DataConfig()\n",
    "\n",
    "parameters = []\n",
    "buffers = []\n",
    "for name, tensor in gradient_data['global_model_state'].items():\n",
    "    if 'running' in name or 'num_batches' in name:\n",
    "        buffers.append(tensor.cuda())\n",
    "    else:\n",
    "        parameters.append(tensor.cuda())\n",
    "\n",
    "print(f\"Parameters: {len(parameters)}\")\n",
    "print(f\"Buffers: {len(buffers)}\")\n",
    "\n",
    "# Format data for Breaching API (server's view)\n",
    "server_payload = [dict(\n",
    "    parameters=parameters,\n",
    "    buffers=buffers,\n",
    "    metadata=data_cfg\n",
    ")]\n",
    "\n",
    "# Format data for Breaching API (attacker's view)\n",
    "shared_data = [dict(\n",
    "    gradients=gradients,\n",
    "    buffers=None,\n",
    "    metadata=dict(\n",
    "        num_data_points=1,\n",
    "        labels=torch.tensor([0]).cuda(),  # Dummy label\n",
    "        local_hyperparams=None\n",
    "    )\n",
    ")]\n",
    "\n",
    "print(\" Data prepared with dummy label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d83ce79-50e1-4e07-80c6-7775e4f03bf5",
   "metadata": {},
   "source": [
    "## 7. Reorder Gradients to Match Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a73a94ec-d880-4bf2-b1fc-44b5d6416505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Reordered 62 gradients to match model\n",
      "\n",
      "Verifying alignment:\n",
      "All shapes match!\n",
      "shared_data updated with correctly ordered gradients\n"
     ]
    }
   ],
   "source": [
    "# Reorder gradients to match model parameter order (critical fix)\n",
    "grad_dict = client_grads['grads_per_step_raw'][0]\n",
    "\n",
    "gradients_ordered = []\n",
    "for name, param in model.named_parameters():\n",
    "    if name in grad_dict:\n",
    "        gradients_ordered.append(grad_dict[name].cuda())\n",
    "    else:\n",
    "        print(f\"Warning: {name} not found in gradients\")\n",
    "\n",
    "print(f\" Reordered {len(gradients_ordered)} gradients to match model\")\n",
    "\n",
    "# Verify shapes match\n",
    "print(\"\\nVerifying alignment:\")\n",
    "for i, (g, p) in enumerate(zip(gradients_ordered, model.parameters())):\n",
    "    if g.shape != p.shape:\n",
    "        print(f\"  Still mismatch at {i}: {g.shape} vs {p.shape}\")\n",
    "        break\n",
    "else:\n",
    "    print(\"All shapes match!\")\n",
    "\n",
    "# gradients and label\n",
    "shared_data = [\n",
    "    dict(\n",
    "        gradients=gradients_ordered,\n",
    "        buffers=None,\n",
    "        metadata=dict(\n",
    "            num_data_points=1,\n",
    "            labels=torch.tensor([0]).cuda(),  # Top-level labels\n",
    "            local_hyperparams=dict(\n",
    "                lr=0.1,\n",
    "                momentum=0.9,\n",
    "                weight_decay=0.0,\n",
    "                steps=1,\n",
    "                data_per_step=32,\n",
    "                labels=[torch.tensor([0]).cuda()],  # Labels list for each step\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "]\n",
    "print(\"shared_data updated with correctly ordered gradients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cba8d0-3ae4-4668-9ef9-edfacb5c8744",
   "metadata": {},
   "source": [
    "## 8. Execute Gradient Inversion Attack\n",
    "**Warning:** This may take several minutes on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61da0ef4-6042-41a3-94d9-b866a9dbf751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Yin attack...\n",
      "This may take several minutes...\n",
      "\n",
      " Attack completed!\n",
      "Reconstructed keys: ['data', 'labels']\n"
     ]
    }
   ],
   "source": [
    "print(\"Running Yin attack...\")\n",
    "print(\"This may take several minutes...\")\n",
    "\n",
    "reconstructed_user_data, stats = attacker.reconstruct(\n",
    "    server_payload,\n",
    "    shared_data,\n",
    "    server_secrets={},\n",
    "    dryrun=False  \n",
    ")\n",
    "\n",
    "print(\"\\n Attack completed!\")\n",
    "print(f\"Reconstructed keys: {list(reconstructed_user_data.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b94aa1-e2c9-4372-80e1-5123d9053079",
   "metadata": {},
   "source": [
    "## 9. Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e70832a0-6925-4571-bec6-9978f2d8956a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructed data shape: torch.Size([1, 3, 32, 32])\n",
      "Reconstructed labels: tensor([0], device='cuda:0')\n",
      "Saved reconstructed image!\n",
      "\n",
      "Image stats:\n",
      "  Min pixel value: -1.8974658250808716\n",
      "  Max pixel value: 2.025352954864502\n",
      "  Mean: 0.037478990852832794\n"
     ]
    }
   ],
   "source": [
    "# Check what was reconstructed\n",
    "print(\"Reconstructed data shape:\", reconstructed_user_data['data'].shape)\n",
    "print(\"Reconstructed labels:\", reconstructed_user_data['labels'])\n",
    "\n",
    "# Save the reconstructed image\n",
    "reconstructed_img = reconstructed_user_data['data']\n",
    "\n",
    "# Save as image file\n",
    "torchvision.utils.save_image(reconstructed_img, 'reconstructed_attack.png')\n",
    "print(\"Saved reconstructed image!\")\n",
    "\n",
    "# Also show some stats\n",
    "print(f\"\\nImage stats:\")\n",
    "print(f\"  Min pixel value: {reconstructed_img.min()}\")\n",
    "print(f\"  Max pixel value: {reconstructed_img.max()}\")\n",
    "print(f\"  Mean: {reconstructed_img.mean()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
