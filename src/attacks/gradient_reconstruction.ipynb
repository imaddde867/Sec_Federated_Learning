{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e11facad-c2f7-41ae-8723-a20790f56253",
   "metadata": {},
   "source": [
    "## Yin Attack (See-Through-Gradients) on CIFAR-100\n",
    "**Objective:** Reconstruct training data from gradients captured during federated learning simulation.\n",
    "**Attack Configuration:**\n",
    "- Target: FL gradients from ResNet18 on CIFAR-100\n",
    "- Batch size: 1\n",
    "- Device: GPU (CUDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f99258-d95d-4a9b-9a76-14ce8222ed2a",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335f7bfb-ae7e-4b18-84d4-382fca626635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import breaching\n",
    "import torchvision.models as models\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ccf515-0c92-4c50-a34d-533ead8a8398",
   "metadata": {},
   "source": [
    "## 2. Configure Breaching Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb97a96c-eb1a-4bee-a123-355c290c70d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Breaching for Yin (See-Through-Gradients) attack\n",
    "cfg = breaching.get_config(overrides=[\"attack=invertinggradients\"])\n",
    "# cfg = breaching.get_config(overrides = [\"attack=yin\"]=\n",
    "print(f\"Attack type:\", {cfg.attack.type})\n",
    "cfg.attack.regularization = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d810f443-1eeb-4363-b0f5-df0fe07c5acf",
   "metadata": {},
   "source": [
    "## 3. Load FL Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755d5875-b694-4425-9ffe-f92fb34fe7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved gradients from FL simulation\n",
    "gradient_dir = Path(\"/scratch/project_2015432/Sec_FL_ritesh/src/fl_simulation/reports/fedavg_baseline/round_00\")\n",
    "gradient_files = sorted(gradient_dir.glob(\"fedavg_metrics_*_tensors.pt\"))\n",
    "grad_file = gradient_files[0]\n",
    "gradient_data = torch.load(grad_file, map_location='cpu')\n",
    "\n",
    "print(f\"Loaded: {grad_file.name}\")\n",
    "print(f\"Keys: {list(gradient_data.keys())}\")\n",
    "print(f\"Clients: {list(gradient_data['raw_gradients'].keys())}\")\n",
    "\n",
    "# Check first client\n",
    "client_id = list(gradient_data['raw_gradients'].keys())[0]\n",
    "client_data = gradient_data['raw_gradients'][client_id]\n",
    "num_steps = len(client_data['grads_per_step_raw'])\n",
    "\n",
    "print(f\"Client {client_id}: {num_steps} gradient steps\")\n",
    "print(f\"Parameters: {len(client_data['grads_per_step_raw'][0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c0e25e-4fb4-4e91-bb0a-661becfd619b",
   "metadata": {},
   "source": [
    "## 4. Load Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7e0159a5-67bd-44e9-8ae4-0bfa2a694f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is loaded\n"
     ]
    }
   ],
   "source": [
    "model_state = gradient_data['global_model_state']\n",
    "model = models.resnet18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 100)  # CIFAR-100 has 100 classes\n",
    "model.load_state_dict(model_state, strict=False)\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "setup = dict(device=torch.device('cuda'), dtype=torch.float32)\n",
    "attacker = breaching.attacks.prepare_attack(model, loss_fn, cfg.attack, setup)\n",
    "\n",
    "print(\"Model is loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4ec454-d2d6-49e0-9c6b-29c1a6ec82e4",
   "metadata": {},
   "source": [
    "## 5. Extract Client Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "be8e1a95-1952-42f5-8897-fc972c1c4bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client: 1\n",
      "Number of gradient tensors: 62\n"
     ]
    }
   ],
   "source": [
    "# Get gradients from first client, first training step\n",
    "client_id = list(gradient_data['raw_gradients'].keys())[0]\n",
    "client_grads = gradient_data['raw_gradients'][client_id]\n",
    "grad_dict = client_grads['grads_per_step_raw'][0]\n",
    "\n",
    "print(f\"Client: {client_id}\")\n",
    "print(f\"Number of gradient tensors: {len(grad_dict)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93558a62-1c0f-402e-bb4b-69e1448cd951",
   "metadata": {},
   "source": [
    "## 6. Prepare Data Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b7599d13-2c56-44f8-a434-4645b233ec98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 62\n",
      "Buffers: 60\n",
      "Data prepared with correct gradients and hyperparams\n"
     ]
    }
   ],
   "source": [
    "# Define CIFAR-100 metadata and separate model parameters/buffers\n",
    "class DataConfig:\n",
    "    modality = \"vision\"\n",
    "    size = (50_000,)\n",
    "    classes = 100\n",
    "    shape = (3, 32, 32)\n",
    "    normalize = True\n",
    "    mean = (0.5071, 0.4867, 0.4408)\n",
    "    std = (0.2675, 0.2565, 0.2761)\n",
    "\n",
    "data_cfg = DataConfig()\n",
    "\n",
    "parameters = []\n",
    "buffers = []\n",
    "for name, tensor in gradient_data['global_model_state'].items():\n",
    "    if 'running' in name or 'num_batches' in name:\n",
    "        buffers.append(tensor.cuda())\n",
    "    else:\n",
    "        parameters.append(tensor.cuda())\n",
    "\n",
    "# Format data for Breaching API (server's view)\n",
    "server_payload = [dict(\n",
    "    parameters=parameters,\n",
    "    buffers=buffers,\n",
    "    metadata=data_cfg\n",
    ")]\n",
    "\n",
    "# Format data for Breaching API (attacker's view)\n",
    "shared_data = [dict(\n",
    "    gradients=gradients_ordered,  # use gradients_ordered \n",
    "    buffers=None,\n",
    "    metadata=dict(\n",
    "        num_data_points=1,\n",
    "        labels=torch.tensor([0]).cuda(),\n",
    "        local_hyperparams=dict(  # add hyperparams to match FL\n",
    "            lr=0.01,\n",
    "            momentum=0.0,\n",
    "            weight_decay=0.0,\n",
    "            steps=1,\n",
    "            data_per_step=1,\n",
    "            labels=[torch.tensor([0]).cuda()],\n",
    "        )\n",
    "    )\n",
    ")]\n",
    "\n",
    "print(f\"Parameters: {len(parameters)}\")\n",
    "print(f\"Buffers: {len(buffers)}\")\n",
    "print(\"Data prepared with correct gradients and hyperparams\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d83ce79-50e1-4e07-80c6-7775e4f03bf5",
   "metadata": {},
   "source": [
    "## 7. Reorder Gradients to Match Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a73a94ec-d880-4bf2-b1fc-44b5d6416505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reordered 62 gradients to match model\n",
      "\n",
      "Verifying alignment:\n",
      "All shapes match!\n",
      "shared_data updated with correctly ordered gradients\n"
     ]
    }
   ],
   "source": [
    "# Reorder gradients to match model parameter order \n",
    "grad_dict = client_grads['grads_per_step_raw'][0]\n",
    "\n",
    "gradients_ordered = []\n",
    "for name, param in model.named_parameters():\n",
    "    if name in grad_dict:\n",
    "        gradients_ordered.append(grad_dict[name].cuda())\n",
    "    else:\n",
    "        print(f\"Warning: {name} not found in gradients\")\n",
    "\n",
    "print(f\"Reordered {len(gradients_ordered)} gradients to match model\")\n",
    "\n",
    "# Verify shapes match\n",
    "print(\"\\nVerifying alignment:\")\n",
    "for i, (g, p) in enumerate(zip(gradients_ordered, model.parameters())):\n",
    "    if g.shape != p.shape:\n",
    "        print(f\"Still mismatch at {i}: {g.shape} vs {p.shape}\")\n",
    "        break\n",
    "else:\n",
    "    print(\"All shapes match!\")\n",
    "\n",
    "# gradients and label - MATCH YOUR FL CONFIG\n",
    "shared_data = [\n",
    "    dict(\n",
    "        gradients=gradients_ordered,\n",
    "        buffers=None,\n",
    "        metadata=dict(\n",
    "            num_data_points=1,\n",
    "            labels=torch.tensor([0]).cuda(),\n",
    "            local_hyperparams=dict(\n",
    "                lr=0.01,          #  matches FL config\n",
    "                momentum=0.0,     # matches your FL config  \n",
    "                weight_decay=0.0,\n",
    "                steps=1,\n",
    "                data_per_step=1,  # matches batch_size=1\n",
    "                labels=[torch.tensor([0]).cuda()],\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"shared_data updated with correctly ordered gradients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cba8d0-3ae4-4668-9ef9-edfacb5c8744",
   "metadata": {},
   "source": [
    "## 8. Execute Gradient Inversion Attack\n",
    "**Warning:** This may take several minutes on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61da0ef4-6042-41a3-94d9-b866a9dbf751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Yin attack...\n",
      "This may take several minutes...\n"
     ]
    }
   ],
   "source": [
    "print(\"Running Yin attack...\")\n",
    "print(\"This may take several minutes...\")\n",
    "\n",
    "reconstructed_user_data, stats = attacker.reconstruct(\n",
    "    server_payload,\n",
    "    shared_data,\n",
    "    server_secrets={},\n",
    "    dryrun=False  \n",
    ")\n",
    "\n",
    "print(\"\\n Attack completed!\")\n",
    "print(f\"Reconstructed keys: {list(reconstructed_user_data.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b94aa1-e2c9-4372-80e1-5123d9053079",
   "metadata": {},
   "source": [
    "## 9. Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70832a0-6925-4571-bec6-9978f2d8956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what was reconstructed\n",
    "print(\"Reconstructed data shape:\", reconstructed_user_data['data'].shape)\n",
    "print(\"Reconstructed labels:\", reconstructed_user_data['labels'])\n",
    "\n",
    "# Save the reconstructed image\n",
    "reconstructed_img = reconstructed_user_data['data']\n",
    "\n",
    "# Save as image file\n",
    "torchvision.utils.save_image(reconstructed_img, 'reconstructed_attack.png')\n",
    "print(\"Saved reconstructed image!\")\n",
    "\n",
    "# Also show some stats\n",
    "print(f\"\\nImage stats:\")\n",
    "print(f\"Min pixel value: {reconstructed_img.min()}\")\n",
    "print(f\"Max pixel value: {reconstructed_img.max()}\")\n",
    "print(f\"Mean: {reconstructed_img.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e634db-c7eb-45d1-97ca-f6b992762269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bfc8f2-aee0-4c95-8ae1-4476eb11ea63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Verify your FL config was actually used\n",
    "print(\"Checking gradient metadata...\")\n",
    "print(f\"Number of steps stored: {num_steps}\")  # Should be 1\n",
    "print(f\"Gradient dict keys sample: {list(grad_dict.keys())[:5]}\")\n",
    "\n",
    "# 2. Check if gradients are actually from batch_size=1\n",
    "first_grad = list(grad_dict.values())[0]\n",
    "print(f\"First gradient shape: {first_grad.shape}\")\n",
    "\n",
    "# 3. Verify the hyperparameters you passed to the attack\n",
    "print(\"\\nHyperparameters passed to attack:\")\n",
    "print(shared_data[0]['metadata']['local_hyperparams'])\n",
    "\n",
    "# 4. Check if model loaded correctly\n",
    "print(f\"\\nModel parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "print(f\"Model on device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec17a2dd-7f87-4868-b874-6325243bed98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this check right before the attack\n",
    "print(\"Model device:\", next(model.parameters()).device)\n",
    "print(\"Gradients device:\", gradients_ordered[0].device)\n",
    "print(\"Setup device:\", setup['device'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
