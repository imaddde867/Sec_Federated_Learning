{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e11facad-c2f7-41ae-8723-a20790f56253",
   "metadata": {},
   "source": [
    "## Yin Attack (InvertingGradients) on CIFAR-100\n",
    "**Objective:** Reconstruct training data from gradients captured during federated learning simulation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f99258-d95d-4a9b-9a76-14ce8222ed2a",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "335f7bfb-ae7e-4b18-84d4-382fca626635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import breaching\n",
    "import breaching.attacks as attacks\n",
    "import breaching.cases as cases\n",
    "import breaching.utils as utils\n",
    "import torchvision.models as models\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ccf515-0c92-4c50-a34d-533ead8a8398",
   "metadata": {},
   "source": [
    "### 2.Attack Configuration\n",
    "This configuration is optimized for the highest possible fidelity, addressing the stability issues (LR), noise/blur (TV), and the architectural defense of ResNet18 (BN Stats).\n",
    "\n",
    "| Parameter | Value | Reason |\n",
    "| :--- | :--- | :--- |\n",
    "| **Attack** | `invertinggradients` | The \"successful\" reconstruction method. |\n",
    "| **Target Model** | ResNet18 | Model architecture. |\n",
    "| **Dataset** | CIFAR-100 |  Target dataset. |\n",
    "| **Batch Size** | 1 | Essential for perfect gradient inversion. |\n",
    "| **Device** | GPU (CUDA) | Used for speed. |\n",
    "| **Max Iterations** | $\\mathbf{20,000}$ | Sufficient time for convergence. |\n",
    "| **Learning Rate (LR)** | $\\mathbf{0.001}$ | Ensures **stability** and high precision. |\n",
    "| **Total Variation (TV)** | $\\mathbf{1e-2}$ | Enforces **sharpness** and smoothness. |\n",
    "| **Critical Fix** | $\\mathbf{+reconstruct\\_bn\\_statistics=True}$ | **Bypasses the Batch Norm defense** for clear reconstruction. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb97a96c-eb1a-4bee-a123-355c290c70d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/rbhandar/.local/lib/python3.12/site-packages/breaching/__init__.py:18: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with hydra.initialize(config_path=\"config\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigating use case single_imagenet with server type honest_but_curious.\n",
      "Attack type: invertinggradients\n",
      "Attack learning rate: 0.001\n",
      "Attack max iterations: 5000\n",
      "Total Variation Reg: 0.01\n"
     ]
    }
   ],
   "source": [
    "cfg = breaching.get_config(overrides=[\n",
    "    \"attack=invertinggradients\",\n",
    "    \"+optim.max_iterations=5000\",         \n",
    "    \"+optim.lr=0.001\",\n",
    "    \"+regularization.total_variation=1e-2\", \n",
    "    \"+reconstruct_bn_statistics=True\"\n",
    "])\n",
    "\n",
    "print(f\"Attack type: {cfg.attack.type}\")\n",
    "if 'optim' in cfg and 'regularization' in cfg:\n",
    "    print(f\"Attack learning rate: {cfg.optim.lr}\")\n",
    "    print(f\"Attack max iterations: {cfg.optim.max_iterations}\")\n",
    "    print(f\"Total Variation Reg: {cfg.regularization.total_variation}\")\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d810f443-1eeb-4363-b0f5-df0fe07c5acf",
   "metadata": {},
   "source": [
    "## 3. Load FL Gradients/ Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "755d5875-b694-4425-9ffe-f92fb34fe7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/rbhandar/.local/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/users/rbhandar/.local/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load saved gradients from FL simulation - CORRECT PATH\n",
    "gradient_dir = Path(\"/scratch/project_2015432/Sec_FL_ritesh/src/attacks/fl_ritesh/reports/fedavg_baseline/round_49\")\n",
    "gradient_files = sorted(gradient_dir.glob(\"fedavg_metrics_*_tensors.pt\"))\n",
    "grad_file = gradient_files[0]\n",
    "gradient_data = torch.load(grad_file, map_location='cpu')\n",
    "\n",
    "model_state = gradient_data['global_model_state']\n",
    "model = models.resnet18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 100)\n",
    "model.load_state_dict(model_state, strict=False)\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "setup = dict(device=torch.device('cuda'), dtype=torch.float32)\n",
    "attacker = breaching.attacks.prepare_attack(model, loss_fn, cfg.attack, setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4ec454-d2d6-49e0-9c6b-29c1a6ec82e4",
   "metadata": {},
   "source": [
    "## 4. Extract Client Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be8e1a95-1952-42f5-8897-fc972c1c4bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client: 0\n",
      "Number of gradient tensors: 62\n"
     ]
    }
   ],
   "source": [
    "# Get gradients from first client, first training step\n",
    "client_id = list(gradient_data['raw_gradients'].keys())[0]\n",
    "client_grads = gradient_data['raw_gradients'][client_id]\n",
    "grad_dict = client_grads['grads_per_step_raw'][0]\n",
    "\n",
    "print(f\"Client: {client_id}\")\n",
    "print(f\"Number of gradient tensors: {len(grad_dict)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93558a62-1c0f-402e-bb4b-69e1448cd951",
   "metadata": {},
   "source": [
    "## 5. Prepare Attack Inputs: Gradients and Model State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7599d13-2c56-44f8-a434-4645b233ec98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 62\n",
      "Buffers: 60\n",
      "Reordered 62 gradients to match model\n",
      "\n",
      "Verifying alignment:\n",
      "All shapes match!\n",
      "server_payload and shared_data created successfully!\n",
      "Using label=0 as initial guess (may not be the actual label)\n"
     ]
    }
   ],
   "source": [
    "# Define CIFAR-100 metadata and separate model parameters/buffers\n",
    "class DataConfig:\n",
    "    modality = \"vision\"\n",
    "    size = (50_000,)\n",
    "    classes = 100\n",
    "    shape = (3, 32, 32)\n",
    "    normalize = True\n",
    "    mean = (0.5071, 0.4867, 0.4408)\n",
    "    std = (0.2675, 0.2565, 0.2761)\n",
    "\n",
    "data_cfg = DataConfig()\n",
    "\n",
    "parameters = []\n",
    "buffers = []\n",
    "for name, tensor in gradient_data['global_model_state'].items():\n",
    "    if 'running' in name or 'num_batches' in name:\n",
    "        buffers.append(tensor.cuda())\n",
    "    else:\n",
    "        parameters.append(tensor.cuda())\n",
    "\n",
    "server_payload = [dict(\n",
    "    parameters=parameters,\n",
    "    buffers=buffers,\n",
    "    metadata=data_cfg\n",
    ")]\n",
    "\n",
    "print(f\"Parameters: {len(parameters)}\")\n",
    "print(f\"Buffers: {len(buffers)}\")\n",
    "\n",
    "# Create gradients_ordered \n",
    "grad_dict = client_grads['grads_per_step_raw'][0]\n",
    "gradients_ordered = []\n",
    "for name, param in model.named_parameters():\n",
    "    if name in grad_dict:\n",
    "        gradients_ordered.append(grad_dict[name].cuda())\n",
    "    else:\n",
    "        print(f\"Warning: {name} not found in gradients\")\n",
    "\n",
    "print(f\"Reordered {len(gradients_ordered)} gradients to match model\")\n",
    "\n",
    "# Verify shapes match\n",
    "print(\"\\nVerifying alignment:\")\n",
    "for i, (g, p) in enumerate(zip(gradients_ordered, model.parameters())):\n",
    "    if g.shape != p.shape:\n",
    "        print(f\"Mismatch at {i}: {g.shape} vs {p.shape}\")\n",
    "        break\n",
    "else:\n",
    "    print(\"All shapes match!\")\n",
    "\n",
    "# Create shared_data - using label 0 as initial guess\n",
    "shared_data = [\n",
    "    dict(\n",
    "        gradients=gradients_ordered,\n",
    "        buffers=None,\n",
    "        metadata=dict(  \n",
    "            num_data_points=1,\n",
    "            labels=torch.tensor([0]).cuda(),  # Starting guess\n",
    "            local_hyperparams=dict(\n",
    "                lr=0.01,\n",
    "                momentum=0.0,\n",
    "                weight_decay=0.0,\n",
    "                steps=1,\n",
    "                data_per_step=1,\n",
    "                labels=[torch.tensor([0]).cuda()],  # Also needed here!\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"server_payload and shared_data created successfully!\")\n",
    "print(\"Using label=0 as initial guess (may not be the actual label)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cba8d0-3ae4-4668-9ef9-edfacb5c8744",
   "metadata": {},
   "source": [
    "## 6. Execute Gradient Inversion Attack\n",
    "**Warning:** This may take several minutes on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61da0ef4-6042-41a3-94d9-b866a9dbf751",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attacking 5 clients\n",
      "Estimated time: ~5 min × 5 = ~25 minutes\n",
      "\n",
      "\n",
      "--------------------\n",
      "CLIENT 0 (1/5)\n",
      "--------------------\n",
      "Running attack (~5 min)...\n"
     ]
    }
   ],
   "source": [
    "client_ids = [0, 6, 7, 12, 10]\n",
    "\n",
    "print(f\"Attacking {len(client_ids)} clients\")\n",
    "print(f\"Estimated time: ~5 min × 5 = ~25 minutes\\n\")\n",
    "\n",
    "\n",
    "# The attack will perform label inference, ignoring this value.\n",
    "LABEL_PLACEHOLDER = torch.tensor([0]).cuda()\n",
    "\n",
    "for idx, cid in enumerate(client_ids):\n",
    "    print(f\"\\n{'-'*20}\")\n",
    "    print(f\"CLIENT {cid} ({idx+1}/5)\")\n",
    "    print(f\"{'-'*20}\")\n",
    "    \n",
    "    client_grads = gradient_data['raw_gradients'][cid]\n",
    "    grad_dict = client_grads['grads_per_step_raw'][0]\n",
    "    \n",
    "    gradients_ordered = []\n",
    "    for name, param in model.named_parameters():\n",
    "        if name in grad_dict:\n",
    "            gradients_ordered.append(grad_dict[name].cuda())\n",
    "    \n",
    "    # Configure payload for label inference\n",
    "    shared_data = [dict(\n",
    "        gradients=gradients_ordered,\n",
    "        buffers=None,\n",
    "        metadata=dict( \n",
    "            num_data_points=1,\n",
    "            labels=LABEL_PLACEHOLDER, \n",
    "            local_hyperparams=dict(\n",
    "                lr=0.01, momentum=0.0, weight_decay=0.0,\n",
    "                steps=1, data_per_step=1,\n",
    "                labels=[LABEL_PLACEHOLDER], \n",
    "            )\n",
    "        )\n",
    "    )]\n",
    "    \n",
    "    print(f\"Running attack (~5 min)...\")\n",
    "    reconstructed_user_data, stats = attacker.reconstruct(\n",
    "        server_payload, shared_data, server_secrets={}, dryrun=False\n",
    "    )\n",
    "    \n",
    "    # Denormalize and process image\n",
    "    reconstructed_img = reconstructed_user_data['data'][0].cpu()\n",
    "    img = reconstructed_img.detach().clone().permute(1, 2, 0)\n",
    "    mean = torch.tensor((0.5071, 0.4867, 0.4408))\n",
    "    std = torch.tensor((0.2675, 0.2565, 0.2761))\n",
    "    img = img * std + mean\n",
    "    img = torch.clamp(img, 0, 1)\n",
    "    \n",
    "    # Save image\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img.numpy())\n",
    "    plt.title(f\"Client {cid} - Reconstructed\", fontsize=14)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f'reconstructed_client_{cid}.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close() \n",
    "    \n",
    "    print(f\"✓ Done! Saved: reconstructed_client_{cid}.png\")\n",
    "    print(f\"  Mean pixel value: {reconstructed_img.mean():.3f}\")\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\n\" + \"-\"*20)\n",
    "print(\"ALL 5 CLIENTS COMPLETED!\")\n",
    "print(\"-\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b94aa1-e2c9-4372-80e1-5123d9053079",
   "metadata": {},
   "source": [
    "## 8. Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70832a0-6925-4571-bec6-9978f2d8956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "\n",
    "for idx, cid in enumerate([0, 6, 7, 12, 10]):\n",
    "    img = Image.open(f'reconstructed_client_{cid}.png')\n",
    "    axes[idx].imshow(img)\n",
    "    axes[idx].set_title(f'Client {cid}', fontsize=14)\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('all_clients_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Saved: all_clients_comparison.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
